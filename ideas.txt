1. pass ROI to the fc layer: right now I am feeding to the fully connected layer the bought price and if it has entered a position. something to think about might be to instead/also pass the current profit margin, ie the current percent return on investment to the fc layer.

2. change the reward function to use percent ROI instead of profit directly: right now the reward is based on the actual return on investment, this will possibly bring problems; when the investment increases, so will the profit, this means that the reward will increase, but the actions the agent are performing arent necesarilly better, they might even be worse, to fix this we should use the percent return on investment instear, this way the reward will remain the same regardless of the magnitude of the investment.

3. modify the reward function to incentivize stop loss and trailing stop loss: the current reward function is only based on absolute profit. if we wish to inject knowledge into the algorithm we might do that by tinkering with the reward function. this might come in the form of a stop loss; meaning that we give negative reward each timestep that the agent is in negative projected profit so that the agent learns to cut its losses early. also a trailing stop loss; meaning that we give negative rewards each timestep that the agent has a decrease in the projected profit, so that the agent learns to take the profit before losing it all. this might also help to incentivize the agent to keep the episode length shorter, meaning more trades per day.