{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype = np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "        \n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "    \n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "        \n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "        \n",
    "        \n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha, \n",
    "                 fc1_dims = 256, fc2_dims = 256, chkpt_dir='tmp/ppo'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        \n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(*input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, n_actions),\n",
    "                nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        print(dist)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims = 256, fc2_dims = 256, \n",
    "                chkpt_dir = 'tmp/ppo'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        self.critic = nn.Sequential(\n",
    "                    nn.Linear(*input_dims, fc1_dims),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(fc1_dims, fc2_dims),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(fc2_dims, 1)\n",
    "            )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "                policy_clip=0.1, batch_size=64, N=2048, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        \n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "        \n",
    "        \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "        \n",
    "    def save_models(self):\n",
    "        print('saving models')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        print('loading models')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation], dtype=T.float).to(self.actor.device)\n",
    "        \n",
    "        dist = self.actor(state)\n",
    "        value = self.critic(state)\n",
    "        \n",
    "        \n",
    "        action = dist.sample()\n",
    "        \n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "        \n",
    "        return action, probs, value\n",
    "    \n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "                reward_arr, dones_arr, batches= self.memory.generate_batches()\n",
    "            \n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "            \n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                                    (1-int(dones_arr[k])) - values[k])\n",
    "                    \n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "            \n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            \n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "                \n",
    "                print(\"states\")\n",
    "                print(states.shape)\n",
    "                print(states)\n",
    "                \n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "                \n",
    "                critic_value = T.squeeze(critic_value)\n",
    "                \n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                \n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip, \n",
    "                                                1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "                \n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "                \n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "            \n",
    "        self.memory.clear_memory()\n",
    "        \n",
    "        \n",
    "    \n",
    "                                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5288, 0.4712]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5271, 0.4729]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5173, 0.4827]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5290, 0.4710]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5270, 0.4730]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5289, 0.4711]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5268, 0.4732]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5287, 0.4713]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5226, 0.4774]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5280, 0.4720]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5218, 0.4782]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5162, 0.4838]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5203, 0.4797]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5149, 0.4851]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5184, 0.4816]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5130, 0.4870]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5106, 0.4894]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5094, 0.4906]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0755, -0.4110,  0.0615,  0.6464],\n",
      "        [-0.0319, -0.0195, -0.0041,  0.0319],\n",
      "        [-0.0428, -0.4095,  0.0119,  0.6119],\n",
      "        [-0.1325, -1.0020,  0.1543,  1.6642],\n",
      "        [-0.0959, -0.4129,  0.0936,  0.6894]])\n",
      "tensor([[0.5203, 0.4797],\n",
      "        [0.5271, 0.4729],\n",
      "        [0.5226, 0.4774],\n",
      "        [0.5094, 0.4906],\n",
      "        [0.5184, 0.4816]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0334, -0.0191, -0.0018,  0.0242],\n",
      "        [-0.0272, -0.0198, -0.0115,  0.0389],\n",
      "        [-0.0338, -0.2142, -0.0013,  0.3163],\n",
      "        [-0.1042, -0.6092,  0.1074,  1.0101],\n",
      "        [-0.0381, -0.0191,  0.0050,  0.0232]])\n",
      "tensor([[0.5133, 0.4867],\n",
      "        [0.5133, 0.4867],\n",
      "        [0.5150, 0.4850],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.5131, 0.4869]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0509, -0.2145,  0.0241,  0.3230],\n",
      "        [-0.0291, -0.2144, -0.0081,  0.3194],\n",
      "        [-0.0634, -0.6055,  0.0430,  0.9253],\n",
      "        [-0.0385, -0.2143,  0.0055,  0.3175],\n",
      "        [-0.0323,  0.1757, -0.0035, -0.2621]])\n",
      "tensor([[0.5164, 0.4836],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.5058, 0.4942],\n",
      "        [0.5169, 0.4831],\n",
      "        [0.5087, 0.4913]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.1163, -0.8055,  0.1276,  1.3345],\n",
      "        [-0.0838, -0.6069,  0.0745,  0.9578],\n",
      "        [-0.0552, -0.4100,  0.0306,  0.6231],\n",
      "        [-0.0287, -0.0194, -0.0087,  0.0295],\n",
      "        [-0.0276, -0.2148, -0.0107,  0.3279]])\n",
      "tensor([[0.4978, 0.5022],\n",
      "        [0.5028, 0.4972],\n",
      "        [0.5101, 0.4899],\n",
      "        [0.5226, 0.4774],\n",
      "        [0.5191, 0.4809]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0385, -0.2143,  0.0055,  0.3175],\n",
      "        [-0.0287, -0.0194, -0.0087,  0.0295],\n",
      "        [-0.0552, -0.4100,  0.0306,  0.6231],\n",
      "        [-0.0334, -0.0191, -0.0018,  0.0242],\n",
      "        [-0.1325, -1.0020,  0.1543,  1.6642]])\n",
      "tensor([[0.5203, 0.4797],\n",
      "        [0.5267, 0.4733],\n",
      "        [0.5093, 0.4907],\n",
      "        [0.5266, 0.4734],\n",
      "        [0.4904, 0.5096]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0838, -0.6069,  0.0745,  0.9578],\n",
      "        [-0.0634, -0.6055,  0.0430,  0.9253],\n",
      "        [-0.0381, -0.0191,  0.0050,  0.0232],\n",
      "        [-0.0272, -0.0198, -0.0115,  0.0389],\n",
      "        [-0.0509, -0.2145,  0.0241,  0.3230]])\n",
      "tensor([[0.5063, 0.4937],\n",
      "        [0.5074, 0.4926],\n",
      "        [0.5343, 0.4657],\n",
      "        [0.5342, 0.4658],\n",
      "        [0.5267, 0.4733]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0755, -0.4110,  0.0615,  0.6464],\n",
      "        [-0.0276, -0.2148, -0.0107,  0.3279],\n",
      "        [-0.0338, -0.2142, -0.0013,  0.3163],\n",
      "        [-0.1042, -0.6092,  0.1074,  1.0101],\n",
      "        [-0.0319, -0.0195, -0.0041,  0.0319]])\n",
      "tensor([[0.5200, 0.4800],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.5344, 0.4656],\n",
      "        [0.5084, 0.4916],\n",
      "        [0.5426, 0.4574]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0959, -0.4129,  0.0936,  0.6894],\n",
      "        [-0.1163, -0.8055,  0.1276,  1.3345],\n",
      "        [-0.0428, -0.4095,  0.0119,  0.6119],\n",
      "        [-0.0291, -0.2144, -0.0081,  0.3194],\n",
      "        [-0.0323,  0.1757, -0.0035, -0.2621]])\n",
      "tensor([[0.5186, 0.4814],\n",
      "        [0.5026, 0.4974],\n",
      "        [0.5222, 0.4778],\n",
      "        [0.5357, 0.4643],\n",
      "        [0.5441, 0.4559]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0323,  0.1757, -0.0035, -0.2621],\n",
      "        [-0.0428, -0.4095,  0.0119,  0.6119],\n",
      "        [-0.0634, -0.6055,  0.0430,  0.9253],\n",
      "        [-0.0385, -0.2143,  0.0055,  0.3175],\n",
      "        [-0.0287, -0.0194, -0.0087,  0.0295]])\n",
      "tensor([[0.5486, 0.4514],\n",
      "        [0.5208, 0.4792],\n",
      "        [0.5086, 0.4914],\n",
      "        [0.5355, 0.4645],\n",
      "        [0.5480, 0.4520]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0838, -0.6069,  0.0745,  0.9578],\n",
      "        [-0.0552, -0.4100,  0.0306,  0.6231],\n",
      "        [-0.0291, -0.2144, -0.0081,  0.3194],\n",
      "        [-0.1325, -1.0020,  0.1543,  1.6642],\n",
      "        [-0.1042, -0.6092,  0.1074,  1.0101]])\n",
      "tensor([[0.5038, 0.4962],\n",
      "        [0.5185, 0.4815],\n",
      "        [0.5361, 0.4639],\n",
      "        [0.4890, 0.5110],\n",
      "        [0.5018, 0.4982]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-1.1634e-01, -8.0555e-01,  1.2760e-01,  1.3345e+00],\n",
      "        [-3.3419e-02, -1.9133e-02, -1.7618e-03,  2.4153e-02],\n",
      "        [-3.8086e-02, -1.9089e-02,  5.0468e-03,  2.3194e-02],\n",
      "        [-3.3802e-02, -2.1423e-01, -1.2788e-03,  3.1628e-01],\n",
      "        [-9.5903e-02, -4.1288e-01,  9.3611e-02,  6.8944e-01]])\n",
      "tensor([[0.4882, 0.5118],\n",
      "        [0.5539, 0.4461],\n",
      "        [0.5538, 0.4462],\n",
      "        [0.5358, 0.4642],\n",
      "        [0.5123, 0.4877]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0276, -0.2148, -0.0107,  0.3279],\n",
      "        [-0.0272, -0.0198, -0.0115,  0.0389],\n",
      "        [-0.0509, -0.2145,  0.0241,  0.3230],\n",
      "        [-0.0319, -0.0195, -0.0041,  0.0319],\n",
      "        [-0.0755, -0.4110,  0.0615,  0.6464]])\n",
      "tensor([[0.5359, 0.4641],\n",
      "        [0.5567, 0.4433],\n",
      "        [0.5359, 0.4641],\n",
      "        [0.5569, 0.4431],\n",
      "        [0.5137, 0.4863]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0276, -0.2148, -0.0107,  0.3279],\n",
      "        [-0.0838, -0.6069,  0.0745,  0.9578],\n",
      "        [-0.0319, -0.0195, -0.0041,  0.0319],\n",
      "        [-0.0385, -0.2143,  0.0055,  0.3175],\n",
      "        [-0.0428, -0.4095,  0.0119,  0.6119]])\n",
      "tensor([[0.5363, 0.4637],\n",
      "        [0.4957, 0.5043],\n",
      "        [0.5595, 0.4405],\n",
      "        [0.5369, 0.4631],\n",
      "        [0.5149, 0.4851]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0272, -0.0198, -0.0115,  0.0389],\n",
      "        [-0.1163, -0.8055,  0.1276,  1.3345],\n",
      "        [-0.0959, -0.4129,  0.0936,  0.6894],\n",
      "        [-0.0291, -0.2144, -0.0081,  0.3194],\n",
      "        [-0.0287, -0.0194, -0.0087,  0.0295]])\n",
      "tensor([[0.5586, 0.4414],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.5054, 0.4946],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.5592, 0.4408]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.1042, -0.6092,  0.1074,  1.0101],\n",
      "        [-0.0552, -0.4100,  0.0306,  0.6231],\n",
      "        [-0.0509, -0.2145,  0.0241,  0.3230],\n",
      "        [-0.0338, -0.2142, -0.0013,  0.3163],\n",
      "        [-0.0323,  0.1757, -0.0035, -0.2621]])\n",
      "tensor([[0.4825, 0.5175],\n",
      "        [0.5068, 0.4932],\n",
      "        [0.5321, 0.4679],\n",
      "        [0.5328, 0.4672],\n",
      "        [0.5731, 0.4269]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.1325, -1.0020,  0.1543,  1.6642],\n",
      "        [-0.0334, -0.0191, -0.0018,  0.0242],\n",
      "        [-0.0381, -0.0191,  0.0050,  0.0232],\n",
      "        [-0.0755, -0.4110,  0.0615,  0.6464],\n",
      "        [-0.0634, -0.6055,  0.0430,  0.9253]])\n",
      "tensor([[0.4581, 0.5419],\n",
      "        [0.5618, 0.4382],\n",
      "        [0.5616, 0.4384],\n",
      "        [0.5039, 0.4961],\n",
      "        [0.4847, 0.5153]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4484, 0.5516]], grad_fn=<SoftmaxBackward>)\n",
      "saving models\n",
      "episode 0 score 21.0 avg score 21.0 time_steps 21 learning_steps 1\n",
      "tensor([[0.5635, 0.4365]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5320, 0.4680]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4841, 0.5159]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4692, 0.5308]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4595, 0.5405]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4512, 0.5488]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4581, 0.5419]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4664, 0.5336]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4563, 0.5437]], grad_fn=<SoftmaxBackward>)\n",
      "episode 1 score 10.0 avg score 15.5 time_steps 31 learning_steps 1\n",
      "tensor([[0.5667, 0.4333]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5801, 0.4199]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5885, 0.4115]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5980, 0.4020]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6137, 0.3863]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5981, 0.4019]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5885, 0.4115]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5987, 0.4013]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5893, 0.4107]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-9.5681e-04,  5.6125e-01, -1.1759e-02, -8.4770e-01],\n",
      "        [ 1.0268e-02,  3.6629e-01, -2.8713e-02, -5.5874e-01],\n",
      "        [-4.3119e-02, -5.9281e-01,  2.5399e-02,  9.2558e-01],\n",
      "        [-3.0981e-02, -7.1087e-03,  5.3378e-03,  3.9912e-02],\n",
      "        [-1.5250e-01, -1.1986e+00,  1.8757e-01,  2.0007e+00]])\n",
      "tensor([[0.5981, 0.4019],\n",
      "        [0.5885, 0.4115],\n",
      "        [0.4841, 0.5159],\n",
      "        [0.5635, 0.4365],\n",
      "        [0.4484, 0.5516]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0707, -0.9839,  0.0684,  1.5322],\n",
      "        [-0.0161,  0.7565,  0.0111, -1.1439],\n",
      "        [-0.1337, -0.7926,  0.1677,  1.3378],\n",
      "        [-0.0311, -0.2023,  0.0061,  0.3343],\n",
      "        [-0.0377, -0.0216,  0.0465, -0.0249]])\n",
      "tensor([[0.4691, 0.5309],\n",
      "        [0.6235, 0.3765],\n",
      "        [0.4749, 0.5251],\n",
      "        [0.5364, 0.4636],\n",
      "        [0.5716, 0.4284]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0550, -0.7883,  0.0439,  1.2261],\n",
      "        [-0.1140, -0.9859,  0.1360,  1.5851],\n",
      "        [ 0.0176,  0.5618, -0.0399, -0.8603],\n",
      "        [-0.1496, -0.9894,  0.1944,  1.6779],\n",
      "        [-0.0381,  0.1728,  0.0460, -0.3025]])\n",
      "tensor([[0.4894, 0.5106],\n",
      "        [0.4837, 0.5163],\n",
      "        [0.6162, 0.3838],\n",
      "        [0.4829, 0.5171],\n",
      "        [0.5910, 0.4090]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0904, -1.1798,  0.0991,  1.8455],\n",
      "        [ 0.0288,  0.3672, -0.0571, -0.5805],\n",
      "        [-0.0347,  0.3672,  0.0399, -0.5804],\n",
      "        [-0.0352, -0.3975,  0.0128,  0.6289],\n",
      "        [-0.0273,  0.5618,  0.0283, -0.8602]])\n",
      "tensor([[0.4937, 0.5063],\n",
      "        [0.6081, 0.3919],\n",
      "        [0.6074, 0.3926],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.6234, 0.3766]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0273,  0.5618,  0.0283, -0.8602],\n",
      "        [-0.0377, -0.0216,  0.0465, -0.0249],\n",
      "        [-0.0311, -0.2023,  0.0061,  0.3343],\n",
      "        [-0.0431, -0.5928,  0.0254,  0.9256],\n",
      "        [-0.0550, -0.7883,  0.0439,  1.2261]])\n",
      "tensor([[0.6243, 0.3757],\n",
      "        [0.5839, 0.4161],\n",
      "        [0.5514, 0.4486],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.5055, 0.4945]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-3.8124e-02,  1.7281e-01,  4.5980e-02, -3.0253e-01],\n",
      "        [-9.5681e-04,  5.6125e-01, -1.1759e-02, -8.4770e-01],\n",
      "        [ 2.8830e-02,  3.6724e-01, -5.7095e-02, -5.8045e-01],\n",
      "        [-1.5250e-01, -1.1986e+00,  1.8757e-01,  2.0007e+00],\n",
      "        [-1.3373e-01, -7.9264e-01,  1.6769e-01,  1.3378e+00]])\n",
      "tensor([[0.5985, 0.4015],\n",
      "        [0.6227, 0.3773],\n",
      "        [0.6092, 0.3908],\n",
      "        [0.5158, 0.4842],\n",
      "        [0.5159, 0.4841]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[ 0.0103,  0.3663, -0.0287, -0.5587],\n",
      "        [-0.0310, -0.0071,  0.0053,  0.0399],\n",
      "        [-0.0161,  0.7565,  0.0111, -1.1439],\n",
      "        [-0.0352, -0.3975,  0.0128,  0.6289],\n",
      "        [ 0.0176,  0.5618, -0.0399, -0.8603]])\n",
      "tensor([[0.6084, 0.3916],\n",
      "        [0.5874, 0.4126],\n",
      "        [0.6440, 0.3560],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.6225, 0.3775]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0707, -0.9839,  0.0684,  1.5322],\n",
      "        [-0.1496, -0.9894,  0.1944,  1.6779],\n",
      "        [-0.0904, -1.1798,  0.0991,  1.8455],\n",
      "        [-0.0347,  0.3672,  0.0399, -0.5804],\n",
      "        [-0.1140, -0.9859,  0.1360,  1.5851]])\n",
      "tensor([[0.5368, 0.4632],\n",
      "        [0.5381, 0.4619],\n",
      "        [0.5406, 0.4594],\n",
      "        [0.6099, 0.3901],\n",
      "        [0.5373, 0.4627]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-1.5250e-01, -1.1986e+00,  1.8757e-01,  2.0007e+00],\n",
      "        [-3.0981e-02, -7.1087e-03,  5.3378e-03,  3.9912e-02],\n",
      "        [ 1.0268e-02,  3.6629e-01, -2.8713e-02, -5.5874e-01],\n",
      "        [-1.1402e-01, -9.8591e-01,  1.3599e-01,  1.5851e+00],\n",
      "        [-9.5681e-04,  5.6125e-01, -1.1759e-02, -8.4770e-01]])\n",
      "tensor([[0.5437, 0.4563],\n",
      "        [0.5926, 0.4074],\n",
      "        [0.6094, 0.3906],\n",
      "        [0.5394, 0.4606],\n",
      "        [0.6225, 0.3775]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0550, -0.7883,  0.0439,  1.2261],\n",
      "        [ 0.0288,  0.3672, -0.0571, -0.5805],\n",
      "        [-0.1337, -0.7926,  0.1677,  1.3378],\n",
      "        [ 0.0176,  0.5618, -0.0399, -0.8603],\n",
      "        [-0.0311, -0.2023,  0.0061,  0.3343]])\n",
      "tensor([[0.5403, 0.4597],\n",
      "        [0.6102, 0.3898],\n",
      "        [0.5395, 0.4605],\n",
      "        [0.6236, 0.3764],\n",
      "        [0.5712, 0.4288]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0904, -1.1798,  0.0991,  1.8455],\n",
      "        [-0.0352, -0.3975,  0.0128,  0.6289],\n",
      "        [-0.0273,  0.5618,  0.0283, -0.8602],\n",
      "        [-0.0161,  0.7565,  0.0111, -1.1439],\n",
      "        [-0.0377, -0.0216,  0.0465, -0.0249]])\n",
      "tensor([[0.5428, 0.4572],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.6239, 0.3761],\n",
      "        [0.6472, 0.3528],\n",
      "        [0.5980, 0.4020]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0381,  0.1728,  0.0460, -0.3025],\n",
      "        [-0.0431, -0.5928,  0.0254,  0.9256],\n",
      "        [-0.1496, -0.9894,  0.1944,  1.6779],\n",
      "        [-0.0347,  0.3672,  0.0399, -0.5804],\n",
      "        [-0.0707, -0.9839,  0.0684,  1.5322]])\n",
      "tensor([[0.6049, 0.3951],\n",
      "        [0.5471, 0.4529],\n",
      "        [0.5389, 0.4611],\n",
      "        [0.6097, 0.3903],\n",
      "        [0.5397, 0.4603]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-7.0741e-02, -9.8393e-01,  6.8434e-02,  1.5322e+00],\n",
      "        [-9.5681e-04,  5.6125e-01, -1.1759e-02, -8.4770e-01],\n",
      "        [-3.8124e-02,  1.7281e-01,  4.5980e-02, -3.0253e-01],\n",
      "        [-1.5250e-01, -1.1986e+00,  1.8757e-01,  2.0007e+00],\n",
      "        [-3.4668e-02,  3.6725e-01,  3.9929e-02, -5.8036e-01]])\n",
      "tensor([[0.5359, 0.4641],\n",
      "        [0.6202, 0.3798],\n",
      "        [0.6033, 0.3967],\n",
      "        [0.5345, 0.4655],\n",
      "        [0.6070, 0.3930]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0310, -0.0071,  0.0053,  0.0399],\n",
      "        [-0.0377, -0.0216,  0.0465, -0.0249],\n",
      "        [-0.1140, -0.9859,  0.1360,  1.5851],\n",
      "        [-0.0904, -1.1798,  0.0991,  1.8455],\n",
      "        [-0.0431, -0.5928,  0.0254,  0.9256]])\n",
      "tensor([[0.5957, 0.4043],\n",
      "        [0.5970, 0.4030],\n",
      "        [0.5311, 0.4689],\n",
      "        [0.5297, 0.4703],\n",
      "        [0.5438, 0.4562]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.0311, -0.2023,  0.0061,  0.3343],\n",
      "        [ 0.0176,  0.5618, -0.0399, -0.8603],\n",
      "        [-0.0550, -0.7883,  0.0439,  1.2261],\n",
      "        [-0.1496, -0.9894,  0.1944,  1.6779],\n",
      "        [ 0.0288,  0.3672, -0.0571, -0.5805]])\n",
      "tensor([[0.5726, 0.4274],\n",
      "        [0.6132, 0.3868],\n",
      "        [0.5295, 0.4705],\n",
      "        [0.5217, 0.4783],\n",
      "        [0.6007, 0.3993]], grad_fn=<SoftmaxBackward>)\n",
      "states\n",
      "torch.Size([5, 4])\n",
      "tensor([[-0.1337, -0.7926,  0.1677,  1.3378],\n",
      "        [-0.0273,  0.5618,  0.0283, -0.8602],\n",
      "        [-0.0352, -0.3975,  0.0128,  0.6289],\n",
      "        [-0.0161,  0.7565,  0.0111, -1.1439],\n",
      "        [ 0.0103,  0.3663, -0.0287, -0.5587]])\n",
      "tensor([[0.5204, 0.4796],\n",
      "        [0.6090, 0.3910],\n",
      "        [0.5508, 0.4492],\n",
      "        [0.6324, 0.3676],\n",
      "        [0.5973, 0.4027]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6088, 0.3912]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6351, 0.3649]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6123, 0.3877]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5985, 0.4015]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5990, 0.4010]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6024, 0.3976]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6230, 0.3770]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6523, 0.3477]], grad_fn=<SoftmaxBackward>)\n",
      "episode 2 score 17.0 avg score 16.0 time_steps 48 learning_steps 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from utils import plot_learning_curve\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N = 20\n",
    "batch_size = 5\n",
    "n_epochs = 4\n",
    "alpha = 0.0003\n",
    "agent = Agent(n_actions=env.action_space.n, batch_size = batch_size,\n",
    "             alpha = alpha, n_epochs = n_epochs, \n",
    "              input_dims = env.observation_space.shape)\n",
    "\n",
    "n_games = 3\n",
    "\n",
    "figure_file = 'plots/cartpole.png'\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        agent.save_models()\n",
    "\n",
    "    print('episode', i, 'score %.1f' %score, 'avg score %.1f' %avg_score, \n",
    "          'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "        \n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, figure_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
