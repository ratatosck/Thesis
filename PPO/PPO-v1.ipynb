{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOMemory:\n",
    "    # will have to add state2[] to account for the other features\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.states2 = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype = np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "        \n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.states2),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "    \n",
    "    def store_memory(self, state, state2, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.states2.append(state2)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "        \n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.states2 = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "        \n",
    "        \n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, alpha,\n",
    "                 in_channels, out_channels, kernel_size, fc_size,\n",
    "                 fc1_dims = 256, fc2_dims = 256, chkpt_dir='tmp/ppo'):\n",
    "        \n",
    "        super(ActorNetwork, self).__init__()\n",
    "        \n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        \n",
    "        # you can try doing sequential block stacking and if you find it hard you can just copy the code from dqn.\n",
    "        # s_stacked = torch.nn.Sequential(s1, s2)\n",
    "        \n",
    "        self.conv_open = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_high = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_low = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_close = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_volume = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        \n",
    "        #revisa si esta parte esta bien, se ve como si le estuvieras haciendo una operacion antes de pasarlo al fc layer. \n",
    "        self.fc_state = nn.Linear(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(fc_size, fc1_dims) #input dims is the sum of all outputs of the conv layers.\n",
    "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
    "        self.fc3 = nn.Linear(fc2_dims, n_actions)\n",
    "        \n",
    "#         self.actor = nn.Sequential(\n",
    "#                 nn.Linear(*input_dims, fc1_dims),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(fc1_dims, fc2_dims),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(fc2_dims, n_actions),\n",
    "#                 nn.Softmax(dim=-1)\n",
    "#         )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, input1, input2, input3, input4, input5, input6):\n",
    "        c1 = self.conv_open(input1.unsqueeze(dim = 1))\n",
    "        c2 = self.conv_high(input2.unsqueeze(dim = 1))\n",
    "        c3 = self.conv_low(input3.unsqueeze(dim = 1))\n",
    "        c4 = self.conv_close(input4.unsqueeze(dim = 1))\n",
    "        c5 = self.conv_volume(input5.unsqueeze(dim = 1))\n",
    "        f1 = self.fc_state(input6)\n",
    "        \n",
    "        combined = T.cat((c1.view(c1.size(0), -1), \n",
    "                  c2.view(c2.size(0), -1),\n",
    "                  c3.view(c3.size(0), -1),\n",
    "                  c4.view(c4.size(0), -1),\n",
    "                  c5.view(c5.size(0), -1),\n",
    "                  f1.view(f1.size(0), -1)), dim=1)\n",
    "        \n",
    "        dist = F.relu(self.fc1(combined))\n",
    "        dist = F.relu(self.fc2(dist))\n",
    "        dist = T.sigmoid(self.fc3(dist))\n",
    "        print('model dist')\n",
    "        print(dist)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, alpha,\n",
    "                 in_channels, out_channels, kernel_size, fc_size,\n",
    "                 fc1_dims = 256, fc2_dims = 256, chkpt_dir = 'tmp/ppo'):\n",
    "        \n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        # you can try doing sequential block stacking and if you find it hard you can just copy the code from dqn.\n",
    "        # s_stacked = torch.nn.Sequential(s1, s2)\n",
    "        \n",
    "        self.conv_open = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_high = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_low = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_close = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_volume = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.fc_state = nn.Linear(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(fc_size, fc1_dims) #input dims is the sum of all outputs of the conv layers.\n",
    "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
    "        self.fc3 = nn.Linear(fc2_dims, 1)\n",
    "        \n",
    "#         self.critic = nn.Sequential(\n",
    "#                     nn.Linear(*input_dims, fc1_dims),\n",
    "#                     nn.ReLU(),\n",
    "#                     nn.Linear(fc1_dims, fc2_dims),\n",
    "#                     nn.ReLU(),\n",
    "#                     nn.Linear(fc2_dims, 1)\n",
    "#             )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, input1, input2, input3, input4, input5, input6):\n",
    "        print('input1')\n",
    "        print(input1)\n",
    "        print(input1.shape)\n",
    "        c1 = self.conv_open(input1.unsqueeze(dim = 1))\n",
    "        c2 = self.conv_high(input2.unsqueeze(dim = 1))\n",
    "        c3 = self.conv_low(input3.unsqueeze(dim = 1))\n",
    "        c4 = self.conv_close(input4.unsqueeze(dim = 1))\n",
    "        c5 = self.conv_volume(input5.unsqueeze(dim = 1))\n",
    "        f1 = self.fc_state(input6)\n",
    "        \n",
    "        combined = T.cat((c1.view(c1.size(0), -1), \n",
    "                  c2.view(c2.size(0), -1),\n",
    "                  c3.view(c3.size(0), -1),\n",
    "                  c4.view(c4.size(0), -1),\n",
    "                  c5.view(c5.size(0), -1),\n",
    "                  f1.view(f1.size(0), -1)), dim=1)\n",
    "        \n",
    "        value = F.relu(self.fc1(combined))\n",
    "        value = F.relu(self.fc2(value))\n",
    "        value = self.fc3(value)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims1, input_dims2, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "                policy_clip=0.1, batch_size=64, N=2048, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        \n",
    "        self.actor = ActorNetwork(n_actions, alpha, 1, 4, 3, 562)\n",
    "        self.critic = CriticNetwork(alpha, 1, 4, 3, 562)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "        \n",
    "        \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state[0], state[1], action, probs, vals, reward, done)\n",
    "        \n",
    "    def save_models(self):\n",
    "        print('saving models')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        print('loading models')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation[0]], dtype=T.float).to(self.actor.device)\n",
    "        state2 = T.tensor([observation[1]], dtype=T.float).to(self.actor.device)\n",
    "        \n",
    "        dist = self.actor(state[:,:,0], \n",
    "                          state[:,:,1], \n",
    "                          state[:,:,2], \n",
    "                          state[:,:,3], \n",
    "                          state[:,:,4],\n",
    "                          state2[:])\n",
    "        \n",
    "        value = self.critic(state[:,:,0], \n",
    "                            state[:,:,1], \n",
    "                            state[:,:,2], \n",
    "                            state[:,:,3], \n",
    "                            state[:,:,4],\n",
    "                            state2[:])\n",
    "#         print(\"printing dist\")\n",
    "#         print(dist)\n",
    "        action = dist.sample()\n",
    "        \n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "        \n",
    "        return action, probs, value\n",
    "    \n",
    "    #***\n",
    "    # lo mas seguro es que el bug esta aqui, en la parte de states, state2 talves no esta pasandolo bien,\n",
    "    # asi que tengo que revisar las dimensiones de las variables para ver que ta pasando y compararlo con\n",
    "    # la version original.\n",
    "    #***\n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, state_arr2, action_arr, old_prob_arr, vals_arr,\\\n",
    "                reward_arr, dones_arr, batches= self.memory.generate_batches()\n",
    "            \n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "            \n",
    "            print(state_arr.shape)\n",
    "            print(state_arr2.shape)\n",
    "            \n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                                    (1-int(dones_arr[k])) - values[k])\n",
    "                    \n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "            \n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            \n",
    "            for batch in batches:\n",
    "                # tienes que revisar las dimensiones de states, \n",
    "                # como es un batch puede salir raro cuando haces el slice.\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                states2 = T.tensor(state_arr2[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "                \n",
    "                #tienes que revisar si esta haciendo esto bien\n",
    "                \n",
    "                dist = self.actor(states[:,:,0], \n",
    "                                  states[:,:,1], \n",
    "                                  states[:,:,2], \n",
    "                                  states[:,:,3], \n",
    "                                  states[:,:,4],\n",
    "                                  states2[:])\n",
    "                \n",
    "                print('distribution')\n",
    "                print(dist)\n",
    "                \n",
    "                critic_value = self.critic(states[:,:,0], \n",
    "                                           states[:,:,1], \n",
    "                                           states[:,:,2], \n",
    "                                           states[:,:,3], \n",
    "                                           states[:,:,4],\n",
    "                                           states2[:])\n",
    "                print('critic_value')\n",
    "                print(critic_value)\n",
    "                critic_value = T.squeeze(critic_value)\n",
    "                \n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                \n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip, \n",
    "                                                1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "                \n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "                \n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "            \n",
    "        self.memory.clear_memory()\n",
    "        \n",
    "        \n",
    "    \n",
    "                                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dist\n",
      "tensor([[4.5730e-03, 1.3732e-18, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.5857e-06, 5.6262e-21, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 5.5699e-23, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 3.5531e-29, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 7.8440e-32, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.0177e-33, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 6.1780e-15, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.3515e-31, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 4.6362e-08, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244,\n",
      "         1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 2.3214e-32, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 9.0606e-36, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[9.9975e-01, 2.0837e-04, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[9.9999e-01, 3.0987e-13, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[9.9988e-01, 1.3154e-27, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[0.9935, 0.9998, 1.0000]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[6.7587e-13, 1.5861e-15, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270,\n",
      "         1.1271, 1.1278, 1.1277]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.4944e-17, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271,\n",
      "         1.1278, 1.1277, 1.1278]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.4360e-30, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278,\n",
      "         1.1277, 1.1278, 1.1279]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[7.0481e-09, 2.2161e-18, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277,\n",
      "         1.1278, 1.1279, 1.1281]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[3.8396e-02, 7.4056e-07, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278,\n",
      "         1.1279, 1.1281, 1.1283]])\n",
      "torch.Size([1, 30])\n",
      "(20, 30, 5)\n",
      "(20, 2)\n",
      "model dist\n",
      "tensor([[9.9975e-01, 2.0837e-04, 1.0000e+00],\n",
      "        [1.0000e+00, 9.0607e-36, 1.0000e+00],\n",
      "        [1.0000e+00, 7.8438e-32, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4359e-30, 1.0000e+00],\n",
      "        [9.9999e-01, 3.0987e-13, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270],\n",
      "        [1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259],\n",
      "        [1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278,\n",
      "         1.1277, 1.1278, 1.1279],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[91.7585],\n",
      "        [12.9672],\n",
      "        [43.0616],\n",
      "        [15.3311],\n",
      "        [87.1607]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[6.0874e-12, 1.1825e-05, 1.0000e+00],\n",
      "        [1.4576e-02, 4.1575e-12, 1.0000e+00],\n",
      "        [8.1965e-01, 2.6892e-19, 1.0000e+00],\n",
      "        [1.0000e+00, 4.9766e-09, 1.0000e+00],\n",
      "        [2.2355e-11, 1.5656e-16, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1243, 1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246],\n",
      "        [1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247],\n",
      "        [1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264],\n",
      "        [1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271,\n",
      "         1.1278, 1.1277, 1.1278],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[ 14.9737],\n",
      "        [-30.2604],\n",
      "        [-54.4230],\n",
      "        [ -2.9637],\n",
      "        [-12.3008]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 3.6551e-20, 1.0000e+00],\n",
      "        [5.3020e-21, 5.8050e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.6643e-17, 1.5816e-09, 1.0000e+00],\n",
      "        [2.3076e-12, 8.3986e-07, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265],\n",
      "        [1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270,\n",
      "         1.1271, 1.1278, 1.1277],\n",
      "        [1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244,\n",
      "         1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264],\n",
      "        [1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277,\n",
      "         1.1278, 1.1279, 1.1281],\n",
      "        [1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[151.6418],\n",
      "        [ -0.7332],\n",
      "        [110.0828],\n",
      "        [-35.9078],\n",
      "        [ 38.2007]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.9915e-18, 1.0000e+00],\n",
      "        [9.9958e-01, 9.9417e-01, 1.0000e+00],\n",
      "        [1.0000e+00, 2.9594e-18, 1.0000e+00],\n",
      "        [8.8836e-05, 7.2716e-01, 1.0000e+00],\n",
      "        [2.8313e-14, 1.0000e+00, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247],\n",
      "        [1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264],\n",
      "        [1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259],\n",
      "        [1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278,\n",
      "         1.1279, 1.1281, 1.1283],\n",
      "        [1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[11.7955],\n",
      "        [14.1999],\n",
      "        [30.5883],\n",
      "        [-9.1374],\n",
      "        [70.5358]], grad_fn=<AddmmBackward>)\n",
      "(20, 30, 5)\n",
      "(20, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dist\n",
      "tensor([[2.7102e-36, 1.0290e-14, 1.0000e+00],\n",
      "        [1.7198e-02, 1.4749e-10, 1.0000e+00],\n",
      "        [1.5305e-01, 3.3844e-16, 1.0000e+00],\n",
      "        [1.8194e-03, 1.0376e-02, 1.0000e+00],\n",
      "        [3.5760e-20, 1.0000e+00, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264],\n",
      "        [1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259],\n",
      "        [1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278,\n",
      "         1.1277, 1.1278, 1.1279],\n",
      "        [1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[ 47.9414],\n",
      "        [-15.6850],\n",
      "        [-40.3672],\n",
      "        [ 65.4125],\n",
      "        [-74.3445]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[9.4436e-22, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 4.3994e-15, 1.0000e+00],\n",
      "        [2.8937e-13, 1.4060e-04, 1.0000e+00],\n",
      "        [3.8553e-04, 1.0000e+00, 1.0000e+00],\n",
      "        [1.4535e-17, 9.9997e-01, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268],\n",
      "        [1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247],\n",
      "        [1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277,\n",
      "         1.1278, 1.1279, 1.1281],\n",
      "        [1.1243, 1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246],\n",
      "        [1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270,\n",
      "         1.1271, 1.1278, 1.1277]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-89.9232],\n",
      "        [ 82.5741],\n",
      "        [  7.0023],\n",
      "        [136.6713],\n",
      "        [ 28.0029]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 7.0788e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 6.8429e-01, 1.0000e+00],\n",
      "        [1.0000e+00, 3.6039e-10, 1.0000e+00],\n",
      "        [1.0000e+00, 3.1435e-10, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270],\n",
      "        [1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244,\n",
      "         1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264],\n",
      "        [1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271,\n",
      "         1.1278, 1.1277, 1.1278],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265],\n",
      "        [1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-45.4582],\n",
      "        [ 35.4066],\n",
      "        [ 71.6188],\n",
      "        [ 34.7646],\n",
      "        [107.3614]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.9150e-12, 1.0000e+00],\n",
      "        [7.2268e-08, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 9.9999e-01, 1.0000e+00],\n",
      "        [9.9823e-01, 8.6911e-03, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247],\n",
      "        [1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278],\n",
      "        [1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264],\n",
      "        [1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278,\n",
      "         1.1279, 1.1281, 1.1283],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[123.9829],\n",
      "        [ 32.9036],\n",
      "        [ 84.9160],\n",
      "        [ 13.9062],\n",
      "        [ 49.7122]], grad_fn=<AddmmBackward>)\n",
      "(20, 30, 5)\n",
      "(20, 2)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 9.0230e-01, 1.0000e+00],\n",
      "        [1.0000e+00, 9.8499e-01, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2961e-08, 1.0000e+00],\n",
      "        [1.0000e+00, 2.5311e-02, 1.0000e+00],\n",
      "        [1.0000e+00, 8.8355e-04, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270],\n",
      "        [1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259],\n",
      "        [1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247],\n",
      "        [1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-36.8087],\n",
      "        [ 49.8802],\n",
      "        [ 95.5923],\n",
      "        [ 56.4274],\n",
      "        [-10.8742]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[4.9322e-02, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 4.6942e-09, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8626e-29, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278],\n",
      "        [1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278,\n",
      "         1.1277, 1.1278, 1.1279],\n",
      "        [1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247],\n",
      "        [1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264],\n",
      "        [1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271,\n",
      "         1.1278, 1.1277, 1.1278]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-16.5778],\n",
      "        [-11.9523],\n",
      "        [  7.3702],\n",
      "        [ 64.5429],\n",
      "        [  8.3989]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 0.9866, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 0.9814, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278,\n",
      "         1.1279, 1.1281, 1.1283],\n",
      "        [1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277,\n",
      "         1.1278, 1.1279, 1.1281],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271],\n",
      "        [1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247],\n",
      "        [1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-6.7910],\n",
      "        [15.5440],\n",
      "        [16.2131],\n",
      "        [ 7.0822],\n",
      "        [15.7099]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268],\n",
      "        [1.1243, 1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246],\n",
      "        [1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244,\n",
      "         1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270],\n",
      "        [1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270,\n",
      "         1.1271, 1.1278, 1.1277]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[-36.9672],\n",
      "        [  1.4615],\n",
      "        [-40.2331],\n",
      "        [-29.9275],\n",
      "        [-28.4883]], grad_fn=<AddmmBackward>)\n",
      "(20, 30, 5)\n",
      "(20, 2)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 2.8383e-05, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259],\n",
      "        [1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244,\n",
      "         1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247],\n",
      "        [1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278,\n",
      "         1.1277, 1.1278, 1.1279],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270],\n",
      "        [1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271,\n",
      "         1.1278, 1.1277, 1.1278]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[27.5048],\n",
      "        [ 6.1743],\n",
      "        [10.3732],\n",
      "        [-5.9987],\n",
      "        [ 1.4853]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000e+00, 9.9942e-01, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 9.9999e-01],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9032e-05, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277,\n",
      "         1.1278, 1.1279, 1.1281],\n",
      "        [1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247],\n",
      "        [1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278,\n",
      "         1.1279, 1.1281, 1.1283],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246,\n",
      "         1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244,\n",
      "         1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264,\n",
      "         1.1264, 1.1265, 1.1270],\n",
      "        [1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1.1259, 1.1259, 1.1264]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[39.4432],\n",
      "        [25.4367],\n",
      "        [ 3.2534],\n",
      "        [50.2903],\n",
      "        [29.0346]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250,\n",
      "         1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268],\n",
      "        [1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243,\n",
      "         1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259],\n",
      "        [1.1243, 1.1238, 1.1241, 1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246],\n",
      "        [1.1242, 1.1242, 1.1243, 1.1240, 1.1243, 1.1243, 1.1244, 1.1243, 1.1244,\n",
      "         1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243,\n",
      "         1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247],\n",
      "        [1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242,\n",
      "         1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[42.4665],\n",
      "        [-7.4618],\n",
      "        [40.4540],\n",
      "        [47.0715],\n",
      "        [ 0.5131]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [0.9057, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]], grad_fn=<SigmoidBackward>)\n",
      "distribution\n",
      "Categorical(probs: torch.Size([5, 3]))\n",
      "input1\n",
      "tensor([[1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241,\n",
      "         1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247,\n",
      "         1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268, 1.1270,\n",
      "         1.1271, 1.1278, 1.1277],\n",
      "        [1.1243, 1.1244, 1.1244, 1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242,\n",
      "         1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271],\n",
      "        [1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244, 1.1246,\n",
      "         1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245,\n",
      "         1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264,\n",
      "         1.1264, 1.1264, 1.1265],\n",
      "        [1.1243, 1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244,\n",
      "         1.1244, 1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245,\n",
      "         1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259,\n",
      "         1.1259, 1.1264, 1.1264],\n",
      "        [1.1243, 1.1244, 1.1243, 1.1244, 1.1244, 1.1243, 1.1244, 1.1244, 1.1244,\n",
      "         1.1246, 1.1246, 1.1250, 1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244,\n",
      "         1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259,\n",
      "         1.1264, 1.1264, 1.1264]])\n",
      "torch.Size([5, 30])\n",
      "critic_value\n",
      "tensor([[ 38.9298],\n",
      "        [ 67.8540],\n",
      "        [ 20.9003],\n",
      "        [102.0898],\n",
      "        [ 30.6692]], grad_fn=<AddmmBackward>)\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1243, 1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245,\n",
      "         1.1246, 1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264,\n",
      "         1.1265, 1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278, 1.1279,\n",
      "         1.1281, 1.1283, 1.1283]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1242, 1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246,\n",
      "         1.1247, 1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265,\n",
      "         1.1270, 1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278, 1.1279, 1.1281,\n",
      "         1.1283, 1.1283, 1.1282]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1242, 1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247,\n",
      "         1.1247, 1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270,\n",
      "         1.1268, 1.1270, 1.1271, 1.1278, 1.1277, 1.1278, 1.1279, 1.1281, 1.1283,\n",
      "         1.1283, 1.1282, 1.1282]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1241, 1.1245, 1.1244, 1.1245, 1.1244, 1.1245, 1.1246, 1.1247, 1.1247,\n",
      "         1.1247, 1.1259, 1.1259, 1.1264, 1.1264, 1.1264, 1.1265, 1.1270, 1.1268,\n",
      "         1.1270, 1.1271, 1.1278, 1.1277, 1.1278, 1.1279, 1.1281, 1.1283, 1.1283,\n",
      "         1.1282, 1.1282, 1.1292]])\n",
      "torch.Size([1, 30])\n",
      "The episode ran for 24 timesteps.\n",
      "episode 0 score -0.6 avg score -0.6 time_steps 24 learning_steps 1\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1282, 1.1285, 1.1285, 1.1285, 1.1279, 1.1280, 1.1282, 1.1277, 1.1270,\n",
      "         1.1272, 1.1273, 1.1279, 1.1276, 1.1275, 1.1268, 1.1261, 1.1253, 1.1257,\n",
      "         1.1260, 1.1265, 1.1256, 1.1260, 1.1258, 1.1257, 1.1262, 1.1257, 1.1261,\n",
      "         1.1266, 1.1274, 1.1274]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1285, 1.1285, 1.1285, 1.1279, 1.1280, 1.1282, 1.1277, 1.1270, 1.1272,\n",
      "         1.1273, 1.1279, 1.1276, 1.1275, 1.1268, 1.1261, 1.1253, 1.1257, 1.1260,\n",
      "         1.1265, 1.1256, 1.1260, 1.1258, 1.1257, 1.1262, 1.1257, 1.1261, 1.1266,\n",
      "         1.1274, 1.1274, 1.1271]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1285, 1.1285, 1.1279, 1.1280, 1.1282, 1.1277, 1.1270, 1.1272, 1.1273,\n",
      "         1.1279, 1.1276, 1.1275, 1.1268, 1.1261, 1.1253, 1.1257, 1.1260, 1.1265,\n",
      "         1.1256, 1.1260, 1.1258, 1.1257, 1.1262, 1.1257, 1.1261, 1.1266, 1.1274,\n",
      "         1.1274, 1.1271, 1.1281]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1285, 1.1279, 1.1280, 1.1282, 1.1277, 1.1270, 1.1272, 1.1273, 1.1279,\n",
      "         1.1276, 1.1275, 1.1268, 1.1261, 1.1253, 1.1257, 1.1260, 1.1265, 1.1256,\n",
      "         1.1260, 1.1258, 1.1257, 1.1262, 1.1257, 1.1261, 1.1266, 1.1274, 1.1274,\n",
      "         1.1271, 1.1281, 1.1319]])\n",
      "torch.Size([1, 30])\n",
      "The episode ran for 4 timesteps.\n",
      "episode 1 score -0.0 avg score -0.3 time_steps 28 learning_steps 1\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1913, 1.1911, 1.1917, 1.1910, 1.1918, 1.1919, 1.1919, 1.1933, 1.1935,\n",
      "         1.1938, 1.1939, 1.1940, 1.1933, 1.1930, 1.1934, 1.1943, 1.1938, 1.1934,\n",
      "         1.1924, 1.1942, 1.1946, 1.1948, 1.1961, 1.1954, 1.1946, 1.1945, 1.1951,\n",
      "         1.1942, 1.1946, 1.1945]])\n",
      "torch.Size([1, 30])\n",
      "model dist\n",
      "tensor([[1., 1., 1.]], grad_fn=<SigmoidBackward>)\n",
      "input1\n",
      "tensor([[1.1911, 1.1917, 1.1910, 1.1918, 1.1919, 1.1919, 1.1933, 1.1935, 1.1938,\n",
      "         1.1939, 1.1940, 1.1933, 1.1930, 1.1934, 1.1943, 1.1938, 1.1934, 1.1924,\n",
      "         1.1942, 1.1946, 1.1948, 1.1961, 1.1954, 1.1946, 1.1945, 1.1951, 1.1942,\n",
      "         1.1946, 1.1945, 1.1944]])\n",
      "torch.Size([1, 30])\n",
      "The episode ran for 2 timesteps.\n",
      "episode 2 score 0.0 avg score -0.2 time_steps 30 learning_steps 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wUdf748debQOgloaYQepEiEFaK5cTCqWcBsR8iKojo977n/TwLnneep+d9ueLXa99TEaQqghKKXUDRO5USErogHVIgoYYSQsr798cMd+u6m8Imu0n2/Xw89rGzM5+Zee9kMu+dz8y+V1QVY4wxkatOuAMwxhgTXpYIjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsJZIoggIvKhiIwNdxy1gYg0FJF3ReS4iLwd5lhGi8gn4YzB1GyWCEJMRPaISL6InBSRAyIyQ0SahGLdqnqdqs4MxboiwK1AW6Clqt4WzkBU9Q1V/WEo1ykiPxGRVBEpEJEZfqZfJSJbReS0iHwmIh28ptUXkddFJM/9H3g0lLGb77NEEB43qmoToD8wAHgqzPHUCCJSN9wxeOkAfKuqRcEuqJq9r/LKAn4LvO47QURaASnAr4BYIBWY59XkWaAbzja8AnhCRK6t4nj9qqHbvvKpqj1C+AD2AFd7vf4D8L7X6xXAeK/X9wL/8nqtwERgO3AU+D9AvNsCf3Kn7Qau87fscrTtBHwBnACWueuZE+A9xQDvAbnust4DEt1pdwKpPu3/H7DEHa7vxrAPOAi8AjR0pw0DMoAngQPA7NLWVZ64gSHAV8AxYD0wrJS/1QXuNjsGbAZucsf/BjgLFAIngXF+5n0WeAfnAHgCSAP6+ewHTwIbgAKgLhAPLHDf227gp27beCAfiPWafwBwCKjnZx+5GFgDHHefLy5l/3v23PYBGgBzgMPue14DtC1jf/4tMMNn3ATgK6/Xjd34e7qvM4Efek1/HngrwPK7Ap+77+UQMM9rWm9gKXDE3Xd+4bVP/RknWWW5w/UD7VPu+BuAde77/gq40Gs9T7oxnwC2AVeF+zhS2Q87IwgjEUkErgN2VHDWG4CLgH7A7cA1XtMG4+ysrXCSzDQRkQDLKa3tm8BqoCXOwWJMKfHUAabjfMJLwvmn/7s7bQnQQ0S6ebX/sbt8gN8D3XHOjroCCcAzXm3b4Xyq7IBzgCltXaXGLSIJwPs4B69Y4DFggYi09n1DIlIPeBf4BGgD/Dfwhoj0UNVfA7/DOSg1UdVpAbbLCOBtd11vAovc5Z5zF3A90AIocde33t0GVwE/E5FrVDUL+Bq4xWcbvqOqhT5xx7rv8a/uNvhf4H0RaRkgRm9jgeZAe3feiTjbt6J6u+8DAFU9BewEeotIDE5iW+/Vfr07jz/P4/wNYoBE4G8AItIUJ9F/5C6vK7DcnedpnITfH+d/ZBDwS69lfmefEpFknDObB3He96vAErcLqwfwE+AiVW2K87+2p0JboyYIdyaKtAfOTnQS59OF4uy8Lbymr6DsM4JLvV7PByZ5td3hNa2R276d77JLa4tzgC0CGnlNn0OAMwI/77E/cNRn3mfc4W7ue28ECHAK6OLVdiiw2x0ehvPJu0F51lVW3Dif7Gb7zP8xMNbPci/D+cRYx2vcXOBZd/jZ0raHO32l1+s6QDZwmdd+cL/X9MHAPp9lPAVMd4fHA5+6wwLsB37gu4/gJL7VPsv5GrjXa72Bzgjux+fTcDn+1v7OCKYBk33GfenG2d7dzxp4TRsO7Amw/FnAFLzO+tzxdwHpAebZCfzI6/U155bvb58CXgae91nGNuBynASTA1wN1CvvdqlpDzsjCI+R6ny6GAb0xPlEXhEHvIZPA038TVPV0+5goIvRgdrGA0e8xoFz4PFLRBqJyKsisldE8nC6ZlqISJTb5E2cf1xwPskucpfdGichrBWRYyJyDOcTnvcn9FxVPVPOdZUVdwfgtnPrctd3KRDn523FA/tVtcRr3F6cT+vl9e91u8vJcJcbKLZ4n9h+gXNBGpxupqEiEg/8AOdg+s8Ace/1GVfeuGfjJMa3RCRLRP7gcwZTXieBZj7jmuF8ADjp9dp3mj9P4CS+1SKyWUTud8e3xzng++O7Dfby3e3+nX0KZ9v/3GfbtwfiVXUH8DOchJkjIm+5f4NaxRJBGKnq58AMnD7yc07hHBzPaRfKmFzZQKyIeMfRvpT2Pwd6AINVtRnOgQqcf2BwTu1biUh/nIRwrlvoEE7XQ29VbeE+mqtzIf0c3/K4pa2rrLj345wRtPB6NFbVyX7eUxbQXkS8/0eScPqKy+vf63aXk+gu1997249zJuQdW1NV/RGAqh7D2Y634yTTuep+dPUTdwefcd5xB9y/VLVQVX+jqr1wrjPcANxT7nf7H5txumQAEJHGQBdgs6oexfk79fNq38+d53tU9YCqPqCq8ThdN/8Qka4426tLgPX7boMkAm933GW94LPtG6nqXDeGN1X1UneZitOdWatYIgi/PwPD3YMkOBesRrmffLsC40IdkKruxbnT41kRiRaRocCNpczSFOeAfszto/61z/KKcD7R/hGnb3apO74EeA14SUTagNOPLyLe1zzKva5yxD0HuFFErhGRKBFpICLD3Gs1vlbhHDSfEJF6IjLMXdZbpcTma6CIjHLvTPkZzkXhlQHargbyRORJ9zsKUSLSR0Qu8mrzJs6B+Rb+k0x9fQB0F5Efi0hdEbkD6IVzUR2c/etO9z15cG6DBUBErhCRvu7ZVR7OxfBifytxl90AiALObctzd+AsBPqIyC1um2eADaq61Z0+C/iliMSISE/gAZwPRP7Wc5vX3+cozoG42H0/7UTkZ25fflMRGey2m+suv7V7B9MzOH/7QF4DJorIYHE0FpHr3WX2EJErRaQ+cAZn3/O7TWoySwRhpqq5OP8Yv3JHvYTTh3kQmAm8EabQRuP01x/G6Qeeh3Mg8+fPQEOcT/grcbp3fL2J08/6tn73lssncS6Wr3S7epbhfOIPpKx1BYxbVffjXMD9Bc6dOfuBx/Hzf6CqZ4GbcC7mHwL+AdzjdTArj8XAHTgHsDHAKPW5uOu1vmKcRNMf546hQ8BUnIu35yzBucZyUFXXf28hznIO43yS/znONngCuEFVD7lNfoXzSfoozt1P3gmlHU7CzgO+wblbJ9AB9Jc4B8VJwN3u8C/dGHJxktUL7noG49w9ds6vcbp19rrr+KOq+ttnwLkpYpWInHTf/yOqultVT+BcW7gRp4tzO86tqOD83VNx7sjaiHPH1m8DLB9VTcVJRn93492Bcz0DnDuQJuP8PQ7g3Djwi0DLqqnO3XZoTKlEZB6wVZ07ZmqMcMUtIs8CXVX17lCu15jzYWcExi8RuUhEuohIHXG+7DMCWBTuuMpSU+M2JpzsW3UmkHY43w5tiXO3y0Oqmh7ekMqlpsZtTNhY15AxxkQ46xoyxpgIF1TXkHv73jygI843Fm937xP2btMf55t7zXBuu3pBVee50zrh3I4Xi3Nlf4x7t0apWrVqpR07dgwmdGOMiThr1649pKrfL6kSTNeQiPwB55uck0VkEhCjqk/6tOkOqKpud7+Rtxa4QFWPich8IEVV3xKRV4D1qvpyWev1eDyampp63nEbY0wkEpG1qurxHR9s19AInHvdcZ9H+jZQ1W9Vdbs7nIVTt6O1iAhwJc59ywHnN8YYU7WCTQRtVTUbwH1uU1pjERkERON8maQlcMzry0UZlFIPRUQmiPNDGKm5ublBhm2MMeacMq8RiMgy/Ne7eboiKxKROJyiVmNVtcQ9I/AVsJ9KVafgVCHE4/HYrU7GGFNJykwEqnp1oGkiclBE4lQ12z3Q5wRo1wynRvovVfVcrZVDOFUj67pnBb4FuYwxxoRAsF1DS3B+zAL3ebFvAxGJxilCNUtV//0j327lxM/4T9Erv/MbY4ypWsEmgsk4lTO34xSAmgwgIh4Rmeq2uR2nVPC9IrLOfZyrtPkk8KiI7MC5ZhDol56MMcZUkRr5zWK7fdQYYyquqm4fNcYYU8VUlbV7j/Dcu1soLC4pe4YKsqJzxhhTTe07fJqU9AwWpmey9/BpGtSrw6jkBPokNC975gqwRGCMMdXI8fxCPtiYTUpaBmv2HEUEhnZuyU+u6Mp1feNoUr/yD9uWCIwxJswKi0v44ttcUtIzWbrlIGeLSujSujGPX9ODkQMSSGjRsErXb4nAGGPCQFXZnJXHgrQMlqzL4vCps8Q2jubHg5IYlZxA34Tm+P/ebeWzRGCMMSGUfTyfRelZpKRlsD3nJNFRdbi6VxtuHpDI5d1bE1039PfwWCIwxpgqdqqgiI82HWBheiZf7jyEKgzsEMMLN/fhhr7xNG9UL6zxWSIwxpgqUFyifL3zMClpGXy46QD5hcW0j23IT6/sxs0DEujYqnG4Q/w3SwTGGFOJvj14ggVpGSxKz+RgXgFNG9Rl5IB4RiUn4ukQE7J+/4qwRGCMMUE6dLKAJeuySEnPYFNmHlF1hGHdW/PMDYlcdUEbGtSLCneIpbJEYIwx5+FMYTHLvjlISlomn3+bS3GJ0jehOc/c0Iub+sfTqkn9cIdYbpYIjDGmnFSVNXuOsjA9g/c2ZHPiTBHtmjXggcs6Myo5ge5tm4Y7xPNiicAYY8qw59ApUtIzWZiewf4j+TSKjuLaPu24JTmRIZ1bElWn+vX7V4QlAmOM8ePY6bO8t8Ep9ZC27xgicGnXVvy/q7tzTe92NK6CUg/hUnveiTHGBOlsUQkrtuWwMD2T5d/kcLa4hO5tmzDpup6M6B9PXPOqLfUQLpYIjDERTVXZkHGclLQMlqzP4ujpQlo1iebuIR0YlZxA7/hm1fKWz8pkicAYE5Eyj+WzKD2TlLQMduaeIrpuHYb3asstyQlc1q019aIi5+dagkoEIhILzAM6AnuA21X1qE+b/sDLQDOgGHhBVee502YAlwPH3eb3quq6YGIyxphAThYU8eHGbFLSMlm5+zCqMKhjLA9c1pnr+sbRvGF4Sz2ES7BnBJOA5ao6WUQmua+f9GlzGrhHVbeLSDywVkQ+VtVj7vTHVfWdIOMwxhi/ikuUf+04REpaBh9vPsCZwhI6tmzEz67qzs0DEkhq2SjcIYZdsIlgBDDMHZ4JrMAnEajqt17DWSKSA7QGjmGMMVXkm+w8FqZnsig9k5wTBTRrUJdbkhMZlZxIclKLWt/vXxHBJoK2qpoNoKrZItKmtMYiMgiIBnZ6jX5BRJ4BlgOTVLUgwLwTgAkASUlJQYZtjKmNck6cYcm6LBakZfJNdh516whX9GzDLckJXNGzDfXrVu9SD+Eiqlp6A5FlQDs/k54GZqpqC6+2R1U1JsBy4nDOGMaq6kqvcQdwksMUYKeqPldW0B6PR1NTU8tqZoyJAPlni/lkywFS0jL55/ZcShT6tW/BqAEJ3NgvntjG0eEOsdoQkbWq6vEdX+YZgapeXcpCD4pInHs2EAfkBGjXDHgf+OW5JOAuO9sdLBCR6cBjZcVjjDElJcrqPUdIScvgg40HOFlQRHzzBjw0rAs3D0ika5sm4Q6xRgm2a2gJMBaY7D4v9m0gItHAQmCWqr7tM+1cEhFgJLApyHiMMbXYztyTLEzLZGF6JpnH8mkcHcWP+sYxKjmRwZ1iqVPDSz2ES7CJYDIwX0TGAfuA2wBExANMVNXxwO3AD4CWInKvO9+520TfEJHWgADrgIlBxmOMqWWOnjrLexucfv91+49RR+DSbq154toe/LBXOxpGW79/sMq8RlAd2TUCY2q3gqJiPtuaS0paBp9ty6GwWOnZrim3JCcyon88bZo1CHeINdJ5XyMwxphQUFXS9x8jJc0p8XzsdCGtm9Zn7NCOjEpOpFd8s3CHWGtZIjDGhNX+I6edUg/pmew+dIr6detwTe92jEpO4NKuragbQaUewsUSgTEm5PLOFPLhxmwWpGWyevcRAIZ0juWhYV24rk87mjaIzFIP4WKJwBgTEkXFJfxz+yFS0jP5ZPMBCopK6NyqMY/9sDsjBySQGGOlHsLFEoExpsqoKluy80hJy2TxuiwOnSygRaN63HFRe0YlJ9IvsbmVeqgGLBEYYyrdwbwzLEp37vffeuAE9aKEq3q2ZVRyAsN6tCG6rvX7VyeWCIwxleL02SI+2XyQBWkZfLnjECUKyUkteH5kH27oG0eMlXqotiwRGGPOW0mJsnLXYRakZfLRpmxOnS0mMaYhP7miKzcnJ9KpVeNwh2jKwRKBMabCduScICXNKfGcdfwMTevX5YYL4xmVnMBFHa3UQ01jicAYUy6HTxbw7vosUtIz2ZBxnKg6wg+6teKpH13A8F5taVDPSj3UVJYIjDEBnSks5tOtOaSkZbBiWy5FJUrv+Gb86oZe3NQvntZN64c7RFMJLBEYY75DVUnbd5QFaZm8tz6LvDNFtG1Wn3GXduLm5AR6trNSD7WNJQJjDAD7Dp8mJT2DhemZ7D18mob1ori2j1Pq4eIurYiyfv9ayxKBMRHseH4h72/IZmF6Bmv2HEUELu7Skp9e2Y1r+rSjSX07REQC+ysbE2EKi0v44ttcUtIyWfrNQc4WldC1TROeuLYHI/snEN+iYbhDNCFmicCYCKCqbMrMY0FaBu+uz+LwqbPENo7mx4OSuCU5kT4JzazUQwSzRGBMLZZ9PJ9F6VmkpGWwPeck0VF1GN6rLTcPSODyHq2pZyWeDZWQCEQkFpgHdAT2ALer6lGfNh2AFCAKqAf8TVVfcacNBGYADYEPgEe0Jv5smjHVxKmCIj7adICU9Ay+2nkYVfB0iOF3N/fl+r5xNG9kJZ7Nd1XGGcEkYLmqThaRSe7rJ33aZAMXq2qBiDQBNonIElXNAl4GJgArcRLBtcCHlRCXMRGjuET5auchFqZl8uGmA+QXFpMU24hHrurGzQMS6NDSSj2YwCojEYwAhrnDM4EV+CQCVT3r9bI+UAdAROKAZqr6tft6FjASSwTGlMu2AydISc9gUXomB/MKaNagLiMHJHBLcgIDO8RYv78pl8pIBG1VNRtAVbNFpI2/RiLSHngf6Ao8rqpZIuIBMryaZQAJAeafgHPmQFJSUiWEbUzNlHuigCXrnX7/zVl51K0jDOvRml/fmMiVPdtYqQdTYeVKBCKyDGjnZ9LT5V2Rqu4HLhSReGCRiLwD+Pu44vf6gKpOAaYAeDweu4ZgIsqZwmKWfXOQlLRMPv82l+IS5cLE5jx7Yy9u7BdPyyZW6sGcv3IlAlW9OtA0ETkoInHu2UAckFPGsrJEZDNwGfAlkOg1ORHIKk9MxtR2JSVK6t6jpKRl8P6GbE4UFBHXvAETftCZUQMS6Na2abhDNLVEZXQNLQHGApPd58W+DUQkETisqvkiEgNcAvyvmzxOiMgQYBVwD/C3SojJmBpr96FTLEzLYOG6TPYfyadRdBTX9YnjluQEBnduaaUeTKWrjEQwGZgvIuOAfcBtAG7//0RVHQ9cALwoIorTHfQnVd3ozv8Q/7l99EPsQrGJQMdOn+W9DdmkpGWQtu8YInBp11Y8Orw71/RuR6No+8qPqTpSE2/Z93g8mpqaGu4wjAnK2aISVmzLISUtk0+35nC2uITubZtwS3IiI/on0K55g3CHaGoZEVmrqh7f8fYxw5gQUlXWZxxnYVoGS9ZncfR0Ia2aRDNmaAduHpBA73gr9WBCzxKBMSGQeSyfRemZLEjLYFfuKerXdUo93JKcyGXdWlHXSj2YMLJEYEwVOXGmkA83HSAlLYOVu44AMKhTLA/+oDPX9Y2jWQMr9WCqB0sExlSiouISvtx5mJS0DD7efIAzhSV0atWYR4d35+YBCbSPbRTuEI35HksExlSSRemZ/O6Db8g5UUDzhvW4dWAio5ITGdC+hfX7m2rNEoExlWD6l7v5zbtbGNghhudG9OGKnq2pX9dKPZiawRKBMUFQVf6yfDt/Xrada3u34y939bcEYGocSwTGnKeSEuW597Yw46s93DYwkf8Z1dfu/jE1kiUCY85DUXEJTy7YyIK0DMZd2omnf3QBdaz0g6mhLBEYU0FnCov56dx0PtlykJ8P785PruxqF4NNjWaJwJgKOFlQxIRZqXy18zC/uak3Yy/uGO6QjAmaJQJjyunoqbPcO2MNmzKP89Id/bh5QGLZMxlTA1giMKYcDuadYcy0Vew5fJpX7x7I1b3ahjskYyqNJQJjyrD38CnunraKIyfPMvO+QQzt0jLcIRlTqSwRGFOKrQfyGDNtNUXFJcydMIQLE1uEOyRjKp3d9GxMAGn7jnLHqyuJEmH+g0MtCZhay84IjPHjX9sPMWF2Km2a1mf2uMFWLM7UakGdEYhIrIgsFZHt7nOMnzYdRGStiKwTkc0iMtFr2goR2eZOWycibYKJx5jK8NGmbO6fsYak2EbMnzjUkoCp9YLtGpoELFfVbsBy97WvbOBiVe0PDAYmiUi81/TRqtrffeQEGY8xQZmfup+H30ijb2Jz5k0YSpum9nORpvYLNhGMAGa6wzOBkb4NVPWsqha4L+tXwjqNqRJT/7mLJ97ZwCVdWzF73CCaN7IfjjGRIdiDcltVzQZwn/127YhIexHZAOwHfq+qWV6Tp7vdQr+SUr6nLyITRCRVRFJzc3ODDNuY/1BV/veTbfz2/W+4vm8cU8d6aBRtl89M5ChzbxeRZUA7P5OeLu9KVHU/cKHbJbRIRN5R1YM43UKZItIUWACMAWYFWMYUYAqAx+PR8q7bmNKUlCi/eXczM7/eyx2e9vxuVF+irHiciTBlJgJVvTrQNBE5KCJxqpotInFAqX38qpolIpuBy4B3VDXTHX9CRN4EBhEgERhT2QqLS3jinQ0sTM9kwg8689R1Pa14nIlIwXYNLQHGusNjgcW+DUQkUUQausMxwCXANhGpKyKt3PH1gBuATUHGY0y5nCks5qE5a1mYnsnj1/SwJGAiWrAdoZOB+SIyDtgH3AYgIh5goqqOBy4AXhQRBQT4k6puFJHGwMduEogClgGvBRmPMWU6caaQB2alsmr3EZ4f2YcxQzqEOyRjwkpUa153u8fj0dTU1HCHYWqgI6fOcu/01WzJyuPF2/sxon9CuEMyJmREZK2qenzH260RJmJkH89nzLTV7D9ymin3DOTKnlZB1BiwRGAixJ5Dpxg9dRXH8wuZef8ghnS2CqLGnGOJwNR6W7LyuOf11ZSoMveBIfRNbB7ukIypViwRmFpt7d4j3Dd9DY3r12X2uCF0bdMk3CEZU+1YIjC11uff5jJx9lraNW/A7HGDSIyx4nHG+GOJwNRKH2zM5pG30unWpikz7x9E66b1wx2SMdWWJQJT68xbs4+nUjaSnBTDtHsvonlDKx5nTGksEZhaZcoXO/ndB1u5vHtrXrl7IA2jo8IdkjHVniUCUyuoKn/6ZBv/99lOrr8wjpdu7090Xat4bkx5WCIwNV5JifLMkk3MWbmPuwYl8duRfayCqDEVYInA1GiFxSU89vZ6Fq/LYuLlXXjy2h5WPM6YCrJEYGqsM4XFPPxGGp9uzeHJa3vy0LAu4Q7JmBrJEoGpkfLOFDJ+Zipr9hzhhZv7MHqwVRA15nxZIjA1zuGTBYydvpqt2Sf4650DuLFffLhDMqZGs0RgapSsY/ncPW0VWcfyeW2shyt6+P2ZbGNMBVgiMDXGrtyTjJm2mrz8QmbdP5hBnWLDHZIxtYIlAlMjbM46ztjXV6MKcycMoU+CVRA1prIE/Y0bEYkVkaUist19jimlbTMRyRSRv3uNGygiG0Vkh4j8VezeP+NjzZ4j3PnqSqKj6vD2xKGWBIypZJXx1ctJwHJV7QYsd18H8jzwuc+4l4EJQDf3cW0lxGRqic+25TBm2ipaN6vPOw9dTOfWVkbamMpWGYlgBDDTHZ4JjPTXSEQGAm2BT7zGxQHNVPVrdX48eVag+U3keXd9Fg/MTKVL6ybMf3Ao8S0ahjskY2qlykgEbVU1G8B9/t5tHCJSB3gReNxnUgKQ4fU6wx33PSIyQURSRSQ1Nze3EsI21dmbq/bx07fSSU6KYe6EIbRqYmWkjakq5bpYLCLLgHZ+Jj1dzvU8DHygqvt9LgH4ux6g/hagqlOAKQAej8dvG1M7vLxiJ7//aCtX9GjNP0ZbBVFjqlq5EoGqXh1omogcFJE4Vc12u3py/DQbClwmIg8DTYBoETkJ/AVI9GqXCGSVO3pTq6gqv/9oG698vpOb+sXz4u39qBdlFUSNqWqV8V+2BBjrDo8FFvs2UNXRqpqkqh2Bx4BZqjrJ7Uo6ISJD3LuF7vE3v6n9ikuUpxdt4pXPdzJ6cBIv3dHfkoAxIVIZ/2mTgeEish0Y7r5GRDwiMrUc8z8ETAV2ADuBDyshJlODnC0q4ZG30nlz1T4eHtbFykgbE2Li3KxTs3g8Hk1NTQ13GKYS5J8t5qE31rJiWy5PXdeTBy+3CqLGVBURWauqHt/x9s1iEzbH8wsZP3MNqXuPMnlUX+4clBTukIyJSJYITFgcOlnAPdNWsz3nBH+/K5nrL4wLd0jGRCxLBCbkMo/lM2bqKrKO5zN17EVc3r11uEMyJqJZIjAhtSPnJGOmreJkQRFzxg3G09EqiBoTbpYITMhsyjzOPa+vpo7AvAlD6RXfLNwhGWOwRGBCZNWuw4yfmUqzhvWYM34wnVo1DndIxhiXJQJT5T7depCH5qSRGNOQOeMHE9fciscZU51YIjBVavG6TH4+fz0XxDVj5v2DiG0cHe6QjDE+LBGYKjN75V6eWbyJQR1jmTrWQ9MG9cIdkjHGD0sEptKpKv9YsZM/fryNqy9ow99/nEyDelZB1JjqyhKBqVSqyuQPt/LqF7sY2T+eP95mFUSNqe4sEZhKU1yiPL1wI2+t2c89Qzvw7I29qWPF44yp9iwRmEpRUFTMo/PW8/7GbP77yq48Orw7Pj9CZIyppiwRmKCdPlvEg7PX8s/th/jl9Rcw/rLO4Q7JGFMBlghMUI6fLuT+mWtI33eUP9xyIbdf1D7cIRljKsgSgTlvuScKGDNtFbtyT/F/P07mur5WQdSYmsgSgTkv+4+cZsy0VRzMK2DavR4u62YVRI2pqYK6r09EYkVkqYhsd59jSqpPhjsAABKbSURBVGnbTEQyReTvXuNWiMg2EVnnPtoEE48JjR05J7jtla85cuosc8YPtiRgTA0X7A3ek4DlqtoNWO6+DuR54HM/40eran/3kRNkPKaKbcg4xm2vfE2xKvMnDmVgh4C53xhTQwSbCEYAM93hmcBIf41EZCDQFvgkyPWZMPp652F+/NoqGtevy9sPDqVnOysjbUxtEGwiaKuq2QDu8/e6dkSkDvAi8HiAZUx3u4V+JaXceC4iE0QkVURSc3NzgwzbVNSyLQcZO301cc0b8M7Ei+loZaSNqTXKvFgsIsuAdn4mPV3OdTwMfKCq+/0c50eraqaINAUWAGOAWf4WoqpTgCkAHo9Hy7luUwkWpmfw2Nsb6BPfjBn3DSLGKogaU6uUmQhU9epA00TkoIjEqWq2iMQB/vr4hwKXicjDQBMgWkROquokVc1013FCRN4EBhEgEZjwmPX1Hp5ZvJmhnVvy2lgPTerbjWbG1DbB/lcvAcYCk93nxb4NVHX0uWERuRfwqOokEakLtFDVQyJSD7gBWBZkPKaSqCp//3QHLy79luG92vK3uwZYBVFjaqlgrxFMBoaLyHZguPsaEfGIyNQy5q0PfCwiG4B1QCbwWpDxmEqgqrzw/je8uPRbRiUn8PJoKyNtTG0mqjWvu93j8Whqamq4w6iViopLeCplI2+vzeDeizvyzA29rIKoMbWEiKxVVY/veOvwNf9WUFTMI3PX8dHmAzxyVTd+dnU3qyBqTASwRGAAOFVQxMQ5TgXRZ27oxf2Xdgp3SMaYELFEYDh2+iz3zVjD+v3H+NNt/bh1YGK4QzLGhJAlggiXk3eGMdNWs/vQKf4xeiDX9vH3lRFjTG1miSCC7T9ymrunrSL3RAHT77uIS7q2CndIxpgwsEQQob49eIK7p66ioKiEN8YPZkCSFY8zJlJZIohA6/Yf497pq4mOqsP8B4fSo13TcIdkjAkjSwQR5qsdh3hgViqxTaJ5Y9wQklo2CndIxpgws0QQQT7ZfICfzE2nU8vGzBo3iLbNGoQ7JGNMNWCJIEIsWJvBEws20DehOTPuu4gWjayCqDHGYYkgAkz/cje/eXcLl3RtyZQxHhpbBVFjjBc7ItRiqspflm/nz8u2c03vtvz1rgHUr2vF44wx32WJoJYqKVGef38L07/cw60DE5k8qi91o4ItNmuMqY0sEdRCRcUlPLlgIwvSMrj/kk788voLrIKoMSYgSwS1zJnCYn46N51Pthzk0eHd+e8ru1oFUWNMqSwR1CInC4qYMCuVr3Ye5tkbe3HvJVZB1BhTtqA6jUUkVkSWish299lvnQIRKRaRde5jidf4TiKyyp1/nojYPY3n6eips4yeuopVu4/wv7f3syRgjCm3YK8eTgKWq2o3YLn72p98Ve3vPm7yGv974CV3/qPAuCDjiUgH885wx5Sv+SY7j5dHJzMq2cpIG2PKL9hEMAKY6Q7PBEaWd0ZxOq6vBN45n/mNY+/hU9z6yldkHs1nxn0X8cPeVkbaGFMxwSaCtqqaDeA+twnQroGIpIrIShE5d7BvCRxT1SL3dQaQEGQ8EWXbgRPc+srXnDhTxJsPDOHiLlZG2hhTcWVeLBaRZYC/j5lPV2A9SaqaJSKdgU9FZCOQ56edlhLHBGACQFJSUgVWXTul7TvKfdPX0KBeHd5+cCjd2loFUWPM+SkzEajq1YGmichBEYlT1WwRiQNyAiwjy33eJSIrgAHAAqCFiNR1zwoSgaxS4pgCTAHweDwBE0Yk+Nf2Q0yYnUrrpvWZM24w7WOtgqgx5vwF2zW0BBjrDo8FFvs2EJEYEanvDrcCLgG2qKoCnwG3lja/+a6PNmVz/4w1JMU24u0Hh1oSMMYELdhEMBkYLiLbgeHua0TEIyJT3TYXAKkish7nwD9ZVbe4054EHhWRHTjXDKYFGU+t9nbqfh5+I40+Cc2YN2EobayMtDGmEojzwbxm8Xg8mpqaGu4wQmrav3bz/HtbuKxbK14dM5BG0fZdQGNMxYjIWlX1+I63o0k1p6q8tPRb/vrpDq7r044/39nfKogaYyqVJYJqrKREee69Lcz4ag+3exL53c1WQdQYU/ksEVRThcUlPPHOBhamZ/LAZZ34xY8usOJxxpgqYYmgGjpTWMxP3kxn2TcHeeyH3fmvK6yCqDGm6lgiqGZOFhQxfuYaVu46wvMjejNmaMdwh2SMqeUsEVQjR06d5d7pq9mclcef7+jPyAFWccMYU/UsEVQTB46f4e5pq9h/5DRTxgzkqgvahjskY0yEsERQDew5dIrRU1dxPL+QmfcPYkjnluEOyRgTQSwRhNk32XmMmbaa4pIS5j4whL6JzcMdkjEmwlgiCKO1e49w3/Q1NK5fl7cmDKVrG6sgaowJPUsEYfLFt7k8OHstbZvVZ874wSTGWPE4Y0x4WCIIgw82ZvPIW+l0bdOUWfcPonXT+uEOyRgTwSwRhNi8Nft4KmUjyUkxTLv3Ipo3rBfukIwxEc4SQQi99sUuXvjgGy7v3pqX7062CqLGmGrBjkQhoKr86ZNt/N9nO7m+bxwv3dGf6LpWPM4YUz1YIqhiJSXKr5dsZvbKvdw1qD2/HdmXqDpWN8gYU31YIqhChcUlPPb2ehavy+LByzsz6dqeVjzOGFPtBNU/ISKxIrJURLa7zzEB2hWLyDr3scRr/AwR2e01rX8w8VQnZwqLeXD2Whavy+KJa3vw1HVWRtoYUz0F21E9CViuqt2A5e5rf/JVtb/7uMln2uNe09YFGU+1cOJMIfe8vprPtuXw25F9eHhY13CHZIwxAQWbCEYAM93hmcDIIJdX4x0+WcBdr60kbe9R/nLnAO4e0iHcIRljTKmCTQRtVTUbwH1uE6BdAxFJFZGVIuKbLF4QkQ0i8pKI1OhvVmUdy+f2V79m+8GTvHaPh5v6xYc7JGOMKVOZF4tFZBnQzs+kpyuwniRVzRKRzsCnIrJRVXcCTwEHgGhgCvAk8FyAOCYAEwCSkpIqsOrQ2JV7kjHTVpOXX8jscYMZ1Ck23CEZY0y5lJkIVPXqQNNE5KCIxKlqtojEATkBlpHlPu8SkRXAAGDnubMJoEBEpgOPlRLHFJxkgcfj0bLiDqXNWccZ+/pqVGHuhCH0SbAKosaYmiPYrqElwFh3eCyw2LeBiMSc6/IRkVbAJcAW93Wc+yw41xc2BRlPyK3Zc4Q7p6wkOqoO8ycOtSRgjKlxgv0ewWRgvoiMA/YBtwGIiAeYqKrjgQuAV0WkBCfxTFbVLe78b4hIa0CAdcDEIOMJqRXbcpg4Zy3xzRsye/xgElo0DHdIxhhTYUElAlU9DFzlZ3wqMN4d/groG2D+K4NZfzi9uz6LR+evo3vbpsy8fxCtmtTo69zGmAhm3yw+D3NX7+MXCzfi6eBUEG3WwCqIGmNqLksEFfTK5zuZ/OFWhvVozcujB9IwOircIRljTFAsEZSTqvKHj7fx8oqd3Ngvnhdv62cVRI0xtYIlgnIoLlF+tXgTb67ax+jBSTw3oo9VEDXG1BqWCMpwtqiER+ev470N2Tw8rAuPX9PDiscZY2oVSwSlyD9bzENvrGXFtlwmXdeTiZd3CXdIxhhT6SwRBJB3ppBxM9aQuvco/zOqL3cNqn5lLYwxpjJYIvDj0MkC7pm2mu05J/jbXQO44UIrHmeMqb0sEfjIPJbPmKmryDqez2v3eBjWI1BBVWOMqR0sEXjZmXuSMVNXcaKgiDnjBuPpaBVEjTG1nyUC16bM49zz+mrqCLw1YQi94614nDEmMlgiAFbtOsz4mak0a1iP2eMG0bl1k3CHZIwxIRPxieCzrU4F0cSYhsweN5h4qyBqjIkwEZ0IFq/L5Ofz19Mzrikz7xtES6sgaoyJQBGbCOas3MuvFm/ioo6xTBvroalVEDXGRKiISwSqyj9W7OSPH2/jyp5t+MfoZBrUswqixpjIFVGJQFWZ/OFWXv1iFyP6x/On2/pRL8oqiBpjIltQR0ERiRWRpSKy3X2OCdAuSUQ+EZFvRGSLiHR0x3cSkVXu/PNEJDqYeEqjqvxi4SZe/WIXY4Z04KXb+1sSMMYYgv/x+knAclXtBix3X/szC/ijql4ADAJy3PG/B15y5z8KjAsynoBEhK5tmvBfV3ThuRG9qWNlpI0xBgBR1fOfWWQbMExVs0UkDlihqj182vQCpqjqpT7jBcgF2qlqkYgMBZ5V1WvKWq/H49HU1NTzjtsYYyKRiKxVVY/v+GDPCNqqajaA++yvME934JiIpIhIuoj8UUSigJbAMVUtcttlAAlBxmOMMaaCyrxYLCLLgHZ+Jj1dgXVcBgwA9gHzgHuBJX7aBjw9EZEJwASApCQrCW2MMZWlzESgqlcHmiYiB0UkzqtrKMdPswwgXVV3ufMsAoYArwMtRKSue1aQCGSVEscUYAo4XUNlxW2MMaZ8gu0aWgKMdYfHAov9tFkDxIhIa/f1lcAWdS5OfAbcWsb8xhhjqlCwiWAyMFxEtgPD3deIiEdEpgKoajHwGLBcRDYCArzmzv8k8KiI7MC5ZjAtyHiMMcZUUFB3DYWL3TVkjDEVV1V3DRljjKnhLBEYY0yEq5FdQyKSC+w9z9lbAYcqMZzKYnFVjMVVMRZXxdTWuDqoamvfkTUyEQRDRFL99ZGFm8VVMRZXxVhcFRNpcVnXkDHGRDhLBMYYE+EiMRFMCXcAAVhcFWNxVYzFVTERFVfEXSMwxhjzXZF4RmCMMcaLJQJjjIlwtSYRiMjrIpIjIpsCTBcR+auI7BCRDSKS7DVtrPtzmdtFZKy/+aswrtFuPBtE5CsR6ec1bY+IbBSRdSJSqTU1yhHXMBE57q57nYg84zXtWhHZ5m7LQL9KV1VxPe4V0yYRKRaRWHdaVW6v9iLymftzq5tF5BE/bUK+j5UzrpDvY+WMK+T7WDnjCvk+JiINRGS1iKx34/qNnzb1xflJ3x3i/MRvR69pT7njt4lImT/u9T2qWisewA+AZGBTgOk/Aj7EKXo3BFjljo8FdrnPMe5wTAjjuvjc+oDrzsXlvt4DtArT9hoGvOdnfBSwE+gMRAPrgV6hisun7Y3ApyHaXnFAsjvcFPjW932HYx8rZ1wh38fKGVfI97HyxBWOfczdZ5q4w/WAVcAQnzYPA6+4w3cC89zhXu42qg90crddVEXWX2vOCFT1C+BIKU1GALPUsRLntxDigGuApap6RFWPAkuBa0MVl6p+5a4XYCXO7zJUuXJsr0AGATtUdZeqngXewtm24YjrLmBuZa27NKqarapp7vAJ4Bu+/4t6Id/HyhNXOPaxcm6vQKpsHzuPuEKyj7n7zEn3ZT334Xsnzwhgpjv8DnCViIg7/i1VLVDV3cAOnG1YbrUmEZRDArDf6/W5n8YMND4cxuF8ojxHgU9EZK04v9AWakPdU9UPRaS3O65abC8RaYRzMF3gNTok28s9JR+A86nNW1j3sVLi8hbyfayMuMK2j5W1vUK9j4lIlIisw/mBr6WqGnD/UufHvI7jlO8PenuV+QtltYj4GaeljA8pEbkC55/0Uq/Rl6hqloi0AZaKyFb3E3MopOHUJTkpIj8CFgHdqCbbC+eU/UtV9T57qPLtJSJNcA4MP1PVPN/JfmYJyT5WRlzn2oR8HysjrrDtY+XZXoR4H1Pnt1v6i0gLYKGI9FFV72tlVbZ/RdIZQQbQ3uv1uZ/GDDQ+ZETkQmAqMEJVD58br6pZ7nMOsJAKnu4FQ1Xzzp2qquoHQD0RaUU12F6uO/E5Za/q7SUi9XAOHm+oaoqfJmHZx8oRV1j2sbLiCtc+Vp7t5Qr5PuYu+xiwgu93H/57u4hIXaA5Tjdq8Nursi96hPMBdCTwxc/r+e6FvNXu+FhgN85FvBh3ODaEcSXh9Old7DO+MdDUa/gr4NoQxtWO/3zhcBCwz912dXEudnbiPxfyeocqLnf6uX+AxqHaXu57nwX8uZQ2Id/HyhlXyPexcsYV8n2sPHGFYx8DWgMt3OGGwD+BG3za/BffvVg83x3uzXcvFu+igheLa03XkIjMxbkLoZWIZAC/xrnggqq+AnyAc1fHDuA0cJ877YiIPI/z28oAz+l3TwWrOq5ncPr5/uFc96FIneqCbXFOD8H5x3hTVT8KYVy3Ag+JSBGQD9ypzl5XJCI/AT7GubvjdVXdHMK4AG4GPlHVU16zVun2Ai4BxgAb3X5cgF/gHGTDuY+VJ65w7GPliSsc+1h54oLQ72NxwEwRicLpqZmvqu+JyHNAqqouwfkp39ni/LTvEZxkgKpuFpH5wBagCPgvdbqZys1KTBhjTISLpGsExhhj/LBEYIwxEc4SgTHGRDhLBMYYE+EsERhjTISzRGCMMRHOEoExxkS4/w+depw2PuWi7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from environment import environment\n",
    "import numpy as np\n",
    "from utils import plot_learning_curve\n",
    "import pandas as pd\n",
    "\n",
    "historical_data = pd.read_csv(r'C:\\Users\\ratatosck\\Desktop\\pythonScripts\\TradeBot\\HistoricalData\\EURUSD15.csv', sep='\\t',header=None)\n",
    "historical_data.drop(0, axis=1, inplace = True)\n",
    "historical_data_np = historical_data.to_numpy(dtype = 'float32')\n",
    "\n",
    "N = 20\n",
    "batch_size = 5\n",
    "n_epochs = 4\n",
    "alpha = 0.0003\n",
    "observation_size = 30\n",
    "\n",
    "env = environment(historical_data_np, observation_size)\n",
    "\n",
    "agent = Agent(n_actions=3, batch_size = batch_size,\n",
    "             alpha = alpha, n_epochs = n_epochs, \n",
    "              input_dims1 = [observation_size, 5], input_dims2 = [2])\n",
    "\n",
    "n_games = 3\n",
    "\n",
    "figure_file = 'plots/PPO-v1.png'\n",
    "\n",
    "# best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "        \n",
    "    #tengo que ver que parametro uso para guardar el modelo.\n",
    "#     if avg_score > best_score:\n",
    "#         best_score = avg_score\n",
    "#         agent.save_models()\n",
    "\n",
    "    print('episode', i, 'score %.1f' %score, 'avg score %.1f' %avg_score, \n",
    "          'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "        \n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, figure_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right now there is a bug. I have checked the shapes of the batches in the replay memory, it seems like the shapes are correct, It looks like im feeding the data into the model correctly, maybe Ill have to check step by step to see what could be wrong. something that is weird though is the output of the sigmoig is 1 on every action, this might be a clue into the identity of the problem. however I have no true idea why it is not working."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
