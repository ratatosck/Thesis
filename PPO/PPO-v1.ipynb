{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype = np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "        \n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "    \n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "        \n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "        \n",
    "        \n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha, \n",
    "                 fc1_dims = 256, fc2_dims = 256, chkpt_dir='tmp/ppo'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        \n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(*input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, n_actions),\n",
    "                nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims = 256, fc2_dims = 256, \n",
    "                chkpt_dir = 'tmp/ppo'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        self.critic = nn.Sequential(\n",
    "                    nn.Linear(*input_dims, fc1_dims),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(fc1_dims, fc2_dims),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(fc2_dims, 1)\n",
    "            )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "        \n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "        \n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "                policy_clip=0.1, batch_size=64, N=2048, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        \n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "        \n",
    "        \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "        \n",
    "    def save_models(self):\n",
    "        print('saving models')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "        \n",
    "    def load_models(self):\n",
    "        print('loading models')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation], dtype=T.float).to(self.actor.device)\n",
    "        \n",
    "        dist = self.actor(state)\n",
    "        value = self.critic(state)\n",
    "        action = dist.sample()\n",
    "        \n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "        \n",
    "        return action, probs, value\n",
    "    \n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "                reward_arr, dones_arr, batches= self.memory.generate_batches()\n",
    "            \n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "            \n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                                    (1-int(dones_arr[k])) - values[k])\n",
    "                    \n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "            \n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            \n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "                \n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "                \n",
    "                critic_value = T.squeeze(critic_value)\n",
    "                \n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                \n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip, \n",
    "                                                1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "                \n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "                \n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "            \n",
    "        self.memory.clear_memory()\n",
    "        \n",
    "        \n",
    "    \n",
    "                                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving models\n",
      "episode 0 score 11.0 avg score 11.0 time_steps 11 learning_steps 0\n",
      "episode 1 score 10.0 avg score 10.5 time_steps 21 learning_steps 1\n",
      "saving models\n",
      "episode 2 score 19.0 avg score 13.3 time_steps 40 learning_steps 2\n",
      "saving models\n",
      "episode 3 score 19.0 avg score 14.8 time_steps 59 learning_steps 2\n",
      "saving models\n",
      "episode 4 score 21.0 avg score 16.0 time_steps 80 learning_steps 4\n",
      "saving models\n",
      "episode 5 score 68.0 avg score 24.7 time_steps 148 learning_steps 7\n",
      "episode 6 score 24.0 avg score 24.6 time_steps 172 learning_steps 8\n",
      "saving models\n",
      "episode 7 score 38.0 avg score 26.2 time_steps 210 learning_steps 10\n",
      "saving models\n",
      "episode 8 score 37.0 avg score 27.4 time_steps 247 learning_steps 12\n",
      "saving models\n",
      "episode 9 score 32.0 avg score 27.9 time_steps 279 learning_steps 13\n",
      "saving models\n",
      "episode 10 score 65.0 avg score 31.3 time_steps 344 learning_steps 17\n",
      "episode 11 score 19.0 avg score 30.2 time_steps 363 learning_steps 18\n",
      "episode 12 score 41.0 avg score 31.1 time_steps 404 learning_steps 20\n",
      "saving models\n",
      "episode 13 score 76.0 avg score 34.3 time_steps 480 learning_steps 24\n",
      "episode 14 score 31.0 avg score 34.1 time_steps 511 learning_steps 25\n",
      "saving models\n",
      "episode 15 score 67.0 avg score 36.1 time_steps 578 learning_steps 28\n",
      "saving models\n",
      "episode 16 score 37.0 avg score 36.2 time_steps 615 learning_steps 30\n",
      "episode 17 score 36.0 avg score 36.2 time_steps 651 learning_steps 32\n",
      "saving models\n",
      "episode 18 score 86.0 avg score 38.8 time_steps 737 learning_steps 36\n",
      "saving models\n",
      "episode 19 score 41.0 avg score 38.9 time_steps 778 learning_steps 38\n",
      "episode 20 score 11.0 avg score 37.6 time_steps 789 learning_steps 39\n",
      "episode 21 score 65.0 avg score 38.8 time_steps 854 learning_steps 42\n",
      "episode 22 score 27.0 avg score 38.3 time_steps 881 learning_steps 44\n",
      "saving models\n",
      "episode 23 score 122.0 avg score 41.8 time_steps 1003 learning_steps 50\n",
      "saving models\n",
      "episode 24 score 48.0 avg score 42.0 time_steps 1051 learning_steps 52\n",
      "saving models\n",
      "episode 25 score 179.0 avg score 47.3 time_steps 1230 learning_steps 61\n",
      "episode 26 score 42.0 avg score 47.1 time_steps 1272 learning_steps 63\n",
      "episode 27 score 19.0 avg score 46.1 time_steps 1291 learning_steps 64\n",
      "saving models\n",
      "episode 28 score 141.0 avg score 49.4 time_steps 1432 learning_steps 71\n",
      "episode 29 score 47.0 avg score 49.3 time_steps 1479 learning_steps 73\n",
      "episode 30 score 19.0 avg score 48.3 time_steps 1498 learning_steps 74\n",
      "episode 31 score 25.0 avg score 47.6 time_steps 1523 learning_steps 76\n",
      "episode 32 score 16.0 avg score 46.6 time_steps 1539 learning_steps 76\n",
      "episode 33 score 50.0 avg score 46.7 time_steps 1589 learning_steps 79\n",
      "episode 34 score 45.0 avg score 46.7 time_steps 1634 learning_steps 81\n",
      "episode 35 score 41.0 avg score 46.5 time_steps 1675 learning_steps 83\n",
      "episode 36 score 107.0 avg score 48.2 time_steps 1782 learning_steps 89\n",
      "episode 37 score 43.0 avg score 48.0 time_steps 1825 learning_steps 91\n",
      "episode 38 score 58.0 avg score 48.3 time_steps 1883 learning_steps 94\n",
      "saving models\n",
      "episode 39 score 149.0 avg score 50.8 time_steps 2032 learning_steps 101\n",
      "saving models\n",
      "episode 40 score 200.0 avg score 54.4 time_steps 2232 learning_steps 111\n",
      "saving models\n",
      "episode 41 score 135.0 avg score 56.4 time_steps 2367 learning_steps 118\n",
      "saving models\n",
      "episode 42 score 132.0 avg score 58.1 time_steps 2499 learning_steps 124\n",
      "saving models\n",
      "episode 43 score 101.0 avg score 59.1 time_steps 2600 learning_steps 130\n",
      "episode 44 score 29.0 avg score 58.4 time_steps 2629 learning_steps 131\n",
      "episode 45 score 60.0 avg score 58.5 time_steps 2689 learning_steps 134\n",
      "saving models\n",
      "episode 46 score 154.0 avg score 60.5 time_steps 2843 learning_steps 142\n",
      "saving models\n",
      "episode 47 score 143.0 avg score 62.2 time_steps 2986 learning_steps 149\n",
      "saving models\n",
      "episode 48 score 104.0 avg score 63.1 time_steps 3090 learning_steps 154\n",
      "saving models\n",
      "episode 49 score 166.0 avg score 65.1 time_steps 3256 learning_steps 162\n",
      "saving models\n",
      "episode 50 score 136.0 avg score 66.5 time_steps 3392 learning_steps 169\n",
      "saving models\n",
      "episode 51 score 126.0 avg score 67.7 time_steps 3518 learning_steps 175\n",
      "saving models\n",
      "episode 52 score 124.0 avg score 68.7 time_steps 3642 learning_steps 182\n",
      "episode 53 score 53.0 avg score 68.4 time_steps 3695 learning_steps 184\n",
      "saving models\n",
      "episode 54 score 153.0 avg score 70.0 time_steps 3848 learning_steps 192\n",
      "saving models\n",
      "episode 55 score 145.0 avg score 71.3 time_steps 3993 learning_steps 199\n",
      "saving models\n",
      "episode 56 score 200.0 avg score 73.6 time_steps 4193 learning_steps 209\n",
      "saving models\n",
      "episode 57 score 200.0 avg score 75.7 time_steps 4393 learning_steps 219\n",
      "episode 58 score 64.0 avg score 75.5 time_steps 4457 learning_steps 222\n",
      "saving models\n",
      "episode 59 score 198.0 avg score 77.6 time_steps 4655 learning_steps 232\n",
      "episode 60 score 20.0 avg score 76.6 time_steps 4675 learning_steps 233\n",
      "episode 61 score 14.0 avg score 75.6 time_steps 4689 learning_steps 234\n",
      "episode 62 score 81.0 avg score 75.7 time_steps 4770 learning_steps 238\n",
      "episode 63 score 147.0 avg score 76.8 time_steps 4917 learning_steps 245\n",
      "saving models\n",
      "episode 64 score 200.0 avg score 78.7 time_steps 5117 learning_steps 255\n",
      "saving models\n",
      "episode 65 score 200.0 avg score 80.6 time_steps 5317 learning_steps 265\n",
      "saving models\n",
      "episode 66 score 186.0 avg score 82.1 time_steps 5503 learning_steps 275\n",
      "saving models\n",
      "episode 67 score 200.0 avg score 83.9 time_steps 5703 learning_steps 285\n",
      "saving models\n",
      "episode 68 score 200.0 avg score 85.6 time_steps 5903 learning_steps 295\n",
      "saving models\n",
      "episode 69 score 86.0 avg score 85.6 time_steps 5989 learning_steps 299\n",
      "saving models\n",
      "episode 70 score 200.0 avg score 87.2 time_steps 6189 learning_steps 309\n",
      "saving models\n",
      "episode 71 score 182.0 avg score 88.5 time_steps 6371 learning_steps 318\n",
      "saving models\n",
      "episode 72 score 149.0 avg score 89.3 time_steps 6520 learning_steps 326\n",
      "saving models\n",
      "episode 73 score 171.0 avg score 90.4 time_steps 6691 learning_steps 334\n",
      "episode 74 score 33.0 avg score 89.7 time_steps 6724 learning_steps 336\n",
      "saving models\n",
      "episode 75 score 200.0 avg score 91.1 time_steps 6924 learning_steps 346\n",
      "saving models\n",
      "episode 76 score 200.0 avg score 92.5 time_steps 7124 learning_steps 356\n",
      "saving models\n",
      "episode 77 score 200.0 avg score 93.9 time_steps 7324 learning_steps 366\n",
      "saving models\n",
      "episode 78 score 200.0 avg score 95.2 time_steps 7524 learning_steps 376\n",
      "saving models\n",
      "episode 79 score 200.0 avg score 96.5 time_steps 7724 learning_steps 386\n",
      "saving models\n",
      "episode 80 score 200.0 avg score 97.8 time_steps 7924 learning_steps 396\n",
      "saving models\n",
      "episode 81 score 200.0 avg score 99.1 time_steps 8124 learning_steps 406\n",
      "episode 82 score 55.0 avg score 98.5 time_steps 8179 learning_steps 408\n",
      "episode 83 score 116.0 avg score 98.8 time_steps 8295 learning_steps 414\n",
      "episode 84 score 34.0 avg score 98.0 time_steps 8329 learning_steps 416\n",
      "episode 85 score 114.0 avg score 98.2 time_steps 8443 learning_steps 422\n",
      "episode 86 score 125.0 avg score 98.5 time_steps 8568 learning_steps 428\n",
      "saving models\n",
      "episode 87 score 182.0 avg score 99.4 time_steps 8750 learning_steps 437\n",
      "saving models\n",
      "episode 88 score 192.0 avg score 100.5 time_steps 8942 learning_steps 447\n",
      "saving models\n",
      "episode 89 score 200.0 avg score 101.6 time_steps 9142 learning_steps 457\n",
      "episode 90 score 77.0 avg score 101.3 time_steps 9219 learning_steps 460\n",
      "episode 91 score 34.0 avg score 100.6 time_steps 9253 learning_steps 462\n",
      "episode 92 score 37.0 avg score 99.9 time_steps 9290 learning_steps 464\n",
      "episode 93 score 103.0 avg score 99.9 time_steps 9393 learning_steps 469\n",
      "episode 94 score 125.0 avg score 100.2 time_steps 9518 learning_steps 475\n",
      "episode 95 score 110.0 avg score 100.3 time_steps 9628 learning_steps 481\n",
      "episode 96 score 132.0 avg score 100.6 time_steps 9760 learning_steps 488\n",
      "saving models\n",
      "episode 97 score 200.0 avg score 101.6 time_steps 9960 learning_steps 498\n",
      "saving models\n",
      "episode 98 score 200.0 avg score 102.6 time_steps 10160 learning_steps 508\n",
      "saving models\n",
      "episode 99 score 200.0 avg score 103.6 time_steps 10360 learning_steps 518\n",
      "saving models\n",
      "episode 100 score 193.0 avg score 105.4 time_steps 10553 learning_steps 527\n",
      "saving models\n",
      "episode 101 score 200.0 avg score 107.3 time_steps 10753 learning_steps 537\n",
      "saving models\n",
      "episode 102 score 200.0 avg score 109.1 time_steps 10953 learning_steps 547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving models\n",
      "episode 103 score 200.0 avg score 110.9 time_steps 11153 learning_steps 557\n",
      "saving models\n",
      "episode 104 score 200.0 avg score 112.7 time_steps 11353 learning_steps 567\n",
      "saving models\n",
      "episode 105 score 200.0 avg score 114.0 time_steps 11553 learning_steps 577\n",
      "saving models\n",
      "episode 106 score 179.0 avg score 115.6 time_steps 11732 learning_steps 586\n",
      "saving models\n",
      "episode 107 score 200.0 avg score 117.2 time_steps 11932 learning_steps 596\n",
      "saving models\n",
      "episode 108 score 200.0 avg score 118.8 time_steps 12132 learning_steps 606\n",
      "saving models\n",
      "episode 109 score 200.0 avg score 120.5 time_steps 12332 learning_steps 616\n",
      "saving models\n",
      "episode 110 score 170.0 avg score 121.6 time_steps 12502 learning_steps 625\n",
      "saving models\n",
      "episode 111 score 200.0 avg score 123.4 time_steps 12702 learning_steps 635\n",
      "saving models\n",
      "episode 112 score 123.0 avg score 124.2 time_steps 12825 learning_steps 641\n",
      "saving models\n",
      "episode 113 score 138.0 avg score 124.8 time_steps 12963 learning_steps 648\n",
      "saving models\n",
      "episode 114 score 157.0 avg score 126.1 time_steps 13120 learning_steps 656\n",
      "saving models\n",
      "episode 115 score 121.0 avg score 126.6 time_steps 13241 learning_steps 662\n",
      "saving models\n",
      "episode 116 score 119.0 avg score 127.5 time_steps 13360 learning_steps 668\n",
      "saving models\n",
      "episode 117 score 112.0 avg score 128.2 time_steps 13472 learning_steps 673\n",
      "saving models\n",
      "episode 118 score 164.0 avg score 129.0 time_steps 13636 learning_steps 681\n",
      "saving models\n",
      "episode 119 score 158.0 avg score 130.2 time_steps 13794 learning_steps 689\n",
      "saving models\n",
      "episode 120 score 164.0 avg score 131.7 time_steps 13958 learning_steps 697\n",
      "saving models\n",
      "episode 121 score 168.0 avg score 132.7 time_steps 14126 learning_steps 706\n",
      "saving models\n",
      "episode 122 score 200.0 avg score 134.4 time_steps 14326 learning_steps 716\n",
      "saving models\n",
      "episode 123 score 200.0 avg score 135.2 time_steps 14526 learning_steps 726\n",
      "saving models\n",
      "episode 124 score 200.0 avg score 136.8 time_steps 14726 learning_steps 736\n",
      "saving models\n",
      "episode 125 score 200.0 avg score 137.0 time_steps 14926 learning_steps 746\n",
      "saving models\n",
      "episode 126 score 200.0 avg score 138.5 time_steps 15126 learning_steps 756\n",
      "saving models\n",
      "episode 127 score 200.0 avg score 140.3 time_steps 15326 learning_steps 766\n",
      "saving models\n",
      "episode 128 score 200.0 avg score 140.9 time_steps 15526 learning_steps 776\n",
      "saving models\n",
      "episode 129 score 200.0 avg score 142.5 time_steps 15726 learning_steps 786\n",
      "saving models\n",
      "episode 130 score 200.0 avg score 144.3 time_steps 15926 learning_steps 796\n",
      "saving models\n",
      "episode 131 score 200.0 avg score 146.0 time_steps 16126 learning_steps 806\n",
      "saving models\n",
      "episode 132 score 200.0 avg score 147.9 time_steps 16326 learning_steps 816\n",
      "saving models\n",
      "episode 133 score 200.0 avg score 149.4 time_steps 16526 learning_steps 826\n",
      "saving models\n",
      "episode 134 score 200.0 avg score 150.9 time_steps 16726 learning_steps 836\n",
      "saving models\n",
      "episode 135 score 188.0 avg score 152.4 time_steps 16914 learning_steps 845\n",
      "saving models\n",
      "episode 136 score 161.0 avg score 152.9 time_steps 17075 learning_steps 853\n",
      "saving models\n",
      "episode 137 score 200.0 avg score 154.5 time_steps 17275 learning_steps 863\n",
      "saving models\n",
      "episode 138 score 200.0 avg score 155.9 time_steps 17475 learning_steps 873\n",
      "saving models\n",
      "episode 139 score 200.0 avg score 156.4 time_steps 17675 learning_steps 883\n",
      "episode 140 score 200.0 avg score 156.4 time_steps 17875 learning_steps 893\n",
      "saving models\n",
      "episode 141 score 200.0 avg score 157.1 time_steps 18075 learning_steps 903\n",
      "saving models\n",
      "episode 142 score 200.0 avg score 157.8 time_steps 18275 learning_steps 913\n",
      "saving models\n",
      "episode 143 score 200.0 avg score 158.8 time_steps 18475 learning_steps 923\n",
      "saving models\n",
      "episode 144 score 200.0 avg score 160.5 time_steps 18675 learning_steps 933\n",
      "saving models\n",
      "episode 145 score 200.0 avg score 161.9 time_steps 18875 learning_steps 943\n",
      "saving models\n",
      "episode 146 score 200.0 avg score 162.3 time_steps 19075 learning_steps 953\n",
      "saving models\n",
      "episode 147 score 200.0 avg score 162.9 time_steps 19275 learning_steps 963\n",
      "saving models\n",
      "episode 148 score 200.0 avg score 163.8 time_steps 19475 learning_steps 973\n",
      "saving models\n",
      "episode 149 score 200.0 avg score 164.2 time_steps 19675 learning_steps 983\n",
      "saving models\n",
      "episode 150 score 194.0 avg score 164.8 time_steps 19869 learning_steps 993\n",
      "saving models\n",
      "episode 151 score 200.0 avg score 165.5 time_steps 20069 learning_steps 1003\n",
      "saving models\n",
      "episode 152 score 200.0 avg score 166.3 time_steps 20269 learning_steps 1013\n",
      "saving models\n",
      "episode 153 score 200.0 avg score 167.7 time_steps 20469 learning_steps 1023\n",
      "saving models\n",
      "episode 154 score 200.0 avg score 168.2 time_steps 20669 learning_steps 1033\n",
      "saving models\n",
      "episode 155 score 200.0 avg score 168.8 time_steps 20869 learning_steps 1043\n",
      "episode 156 score 200.0 avg score 168.8 time_steps 21069 learning_steps 1053\n",
      "episode 157 score 200.0 avg score 168.8 time_steps 21269 learning_steps 1063\n",
      "saving models\n",
      "episode 158 score 200.0 avg score 170.1 time_steps 21469 learning_steps 1073\n",
      "saving models\n",
      "episode 159 score 200.0 avg score 170.1 time_steps 21669 learning_steps 1083\n",
      "saving models\n",
      "episode 160 score 200.0 avg score 171.9 time_steps 21869 learning_steps 1093\n",
      "saving models\n",
      "episode 161 score 200.0 avg score 173.8 time_steps 22069 learning_steps 1103\n",
      "saving models\n",
      "episode 162 score 200.0 avg score 175.0 time_steps 22269 learning_steps 1113\n",
      "saving models\n",
      "episode 163 score 200.0 avg score 175.5 time_steps 22469 learning_steps 1123\n",
      "episode 164 score 200.0 avg score 175.5 time_steps 22669 learning_steps 1133\n",
      "episode 165 score 200.0 avg score 175.5 time_steps 22869 learning_steps 1143\n",
      "saving models\n",
      "episode 166 score 200.0 avg score 175.7 time_steps 23069 learning_steps 1153\n",
      "episode 167 score 200.0 avg score 175.7 time_steps 23269 learning_steps 1163\n",
      "episode 168 score 200.0 avg score 175.7 time_steps 23469 learning_steps 1173\n",
      "saving models\n",
      "episode 169 score 159.0 avg score 176.4 time_steps 23628 learning_steps 1181\n",
      "episode 170 score 200.0 avg score 176.4 time_steps 23828 learning_steps 1191\n",
      "saving models\n",
      "episode 171 score 200.0 avg score 176.6 time_steps 24028 learning_steps 1201\n",
      "saving models\n",
      "episode 172 score 200.0 avg score 177.1 time_steps 24228 learning_steps 1211\n",
      "saving models\n",
      "episode 173 score 200.0 avg score 177.4 time_steps 24428 learning_steps 1221\n",
      "saving models\n",
      "episode 174 score 200.0 avg score 179.0 time_steps 24628 learning_steps 1231\n",
      "episode 175 score 189.0 avg score 178.9 time_steps 24817 learning_steps 1240\n",
      "episode 176 score 200.0 avg score 178.9 time_steps 25017 learning_steps 1250\n",
      "episode 177 score 200.0 avg score 178.9 time_steps 25217 learning_steps 1260\n",
      "episode 178 score 200.0 avg score 178.9 time_steps 25417 learning_steps 1270\n",
      "episode 179 score 200.0 avg score 178.9 time_steps 25617 learning_steps 1280\n",
      "episode 180 score 200.0 avg score 178.9 time_steps 25817 learning_steps 1290\n",
      "episode 181 score 200.0 avg score 178.9 time_steps 26017 learning_steps 1300\n",
      "saving models\n",
      "episode 182 score 82.0 avg score 179.2 time_steps 26099 learning_steps 1304\n",
      "episode 183 score 56.0 avg score 178.6 time_steps 26155 learning_steps 1307\n",
      "saving models\n",
      "episode 184 score 144.0 avg score 179.7 time_steps 26299 learning_steps 1314\n",
      "saving models\n",
      "episode 185 score 200.0 avg score 180.6 time_steps 26499 learning_steps 1324\n",
      "saving models\n",
      "episode 186 score 200.0 avg score 181.3 time_steps 26699 learning_steps 1334\n",
      "episode 187 score 82.0 avg score 180.3 time_steps 26781 learning_steps 1339\n",
      "episode 188 score 200.0 avg score 180.4 time_steps 26981 learning_steps 1349\n",
      "episode 189 score 200.0 avg score 180.4 time_steps 27181 learning_steps 1359\n",
      "episode 190 score 120.0 avg score 180.8 time_steps 27301 learning_steps 1365\n",
      "saving models\n",
      "episode 191 score 200.0 avg score 182.5 time_steps 27501 learning_steps 1375\n",
      "saving models\n",
      "episode 192 score 200.0 avg score 184.1 time_steps 27701 learning_steps 1385\n",
      "episode 193 score 30.0 avg score 183.4 time_steps 27731 learning_steps 1386\n",
      "saving models\n",
      "episode 194 score 200.0 avg score 184.1 time_steps 27931 learning_steps 1396\n",
      "saving models\n",
      "episode 195 score 200.0 avg score 185.0 time_steps 28131 learning_steps 1406\n",
      "saving models\n",
      "episode 196 score 200.0 avg score 185.7 time_steps 28331 learning_steps 1416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 197 score 200.0 avg score 185.7 time_steps 28531 learning_steps 1426\n",
      "episode 198 score 200.0 avg score 185.7 time_steps 28731 learning_steps 1436\n",
      "episode 199 score 200.0 avg score 185.7 time_steps 28931 learning_steps 1446\n",
      "saving models\n",
      "episode 200 score 200.0 avg score 185.8 time_steps 29131 learning_steps 1456\n",
      "episode 201 score 200.0 avg score 185.8 time_steps 29331 learning_steps 1466\n",
      "episode 202 score 200.0 avg score 185.8 time_steps 29531 learning_steps 1476\n",
      "episode 203 score 200.0 avg score 185.8 time_steps 29731 learning_steps 1486\n",
      "episode 204 score 200.0 avg score 185.8 time_steps 29931 learning_steps 1496\n",
      "episode 205 score 200.0 avg score 185.8 time_steps 30131 learning_steps 1506\n",
      "saving models\n",
      "episode 206 score 200.0 avg score 186.0 time_steps 30331 learning_steps 1516\n",
      "episode 207 score 200.0 avg score 186.0 time_steps 30531 learning_steps 1526\n",
      "episode 208 score 200.0 avg score 186.0 time_steps 30731 learning_steps 1536\n",
      "episode 209 score 200.0 avg score 186.0 time_steps 30931 learning_steps 1546\n",
      "saving models\n",
      "episode 210 score 200.0 avg score 186.3 time_steps 31131 learning_steps 1556\n",
      "episode 211 score 200.0 avg score 186.3 time_steps 31331 learning_steps 1566\n",
      "saving models\n",
      "episode 212 score 200.0 avg score 187.1 time_steps 31531 learning_steps 1576\n",
      "saving models\n",
      "episode 213 score 200.0 avg score 187.7 time_steps 31731 learning_steps 1586\n",
      "saving models\n",
      "episode 214 score 200.0 avg score 188.1 time_steps 31931 learning_steps 1596\n",
      "saving models\n",
      "episode 215 score 200.0 avg score 188.9 time_steps 32131 learning_steps 1606\n",
      "saving models\n",
      "episode 216 score 200.0 avg score 189.7 time_steps 32331 learning_steps 1616\n",
      "saving models\n",
      "episode 217 score 200.0 avg score 190.6 time_steps 32531 learning_steps 1626\n",
      "saving models\n",
      "episode 218 score 200.0 avg score 190.9 time_steps 32731 learning_steps 1636\n",
      "saving models\n",
      "episode 219 score 200.0 avg score 191.4 time_steps 32931 learning_steps 1646\n",
      "saving models\n",
      "episode 220 score 200.0 avg score 191.7 time_steps 33131 learning_steps 1656\n",
      "saving models\n",
      "episode 221 score 200.0 avg score 192.1 time_steps 33331 learning_steps 1666\n",
      "episode 222 score 200.0 avg score 192.1 time_steps 33531 learning_steps 1676\n",
      "episode 223 score 200.0 avg score 192.1 time_steps 33731 learning_steps 1686\n",
      "episode 224 score 200.0 avg score 192.1 time_steps 33931 learning_steps 1696\n",
      "episode 225 score 200.0 avg score 192.1 time_steps 34131 learning_steps 1706\n",
      "episode 226 score 200.0 avg score 192.1 time_steps 34331 learning_steps 1716\n",
      "episode 227 score 200.0 avg score 192.1 time_steps 34531 learning_steps 1726\n",
      "episode 228 score 200.0 avg score 192.1 time_steps 34731 learning_steps 1736\n",
      "episode 229 score 200.0 avg score 192.1 time_steps 34931 learning_steps 1746\n",
      "episode 230 score 200.0 avg score 192.1 time_steps 35131 learning_steps 1756\n",
      "episode 231 score 200.0 avg score 192.1 time_steps 35331 learning_steps 1766\n",
      "episode 232 score 200.0 avg score 192.1 time_steps 35531 learning_steps 1776\n",
      "episode 233 score 200.0 avg score 192.1 time_steps 35731 learning_steps 1786\n",
      "episode 234 score 200.0 avg score 192.1 time_steps 35931 learning_steps 1796\n",
      "saving models\n",
      "episode 235 score 200.0 avg score 192.2 time_steps 36131 learning_steps 1806\n",
      "saving models\n",
      "episode 236 score 200.0 avg score 192.6 time_steps 36331 learning_steps 1816\n",
      "episode 237 score 200.0 avg score 192.6 time_steps 36531 learning_steps 1826\n",
      "episode 238 score 73.0 avg score 191.3 time_steps 36604 learning_steps 1830\n",
      "episode 239 score 76.0 avg score 190.1 time_steps 36680 learning_steps 1834\n",
      "episode 240 score 200.0 avg score 190.1 time_steps 36880 learning_steps 1844\n",
      "episode 241 score 200.0 avg score 190.1 time_steps 37080 learning_steps 1854\n",
      "episode 242 score 200.0 avg score 190.1 time_steps 37280 learning_steps 1864\n",
      "episode 243 score 200.0 avg score 190.1 time_steps 37480 learning_steps 1874\n",
      "episode 244 score 200.0 avg score 190.1 time_steps 37680 learning_steps 1884\n",
      "episode 245 score 200.0 avg score 190.1 time_steps 37880 learning_steps 1894\n",
      "episode 246 score 200.0 avg score 190.1 time_steps 38080 learning_steps 1904\n",
      "episode 247 score 200.0 avg score 190.1 time_steps 38280 learning_steps 1914\n",
      "episode 248 score 200.0 avg score 190.1 time_steps 38480 learning_steps 1924\n",
      "episode 249 score 200.0 avg score 190.1 time_steps 38680 learning_steps 1934\n",
      "episode 250 score 200.0 avg score 190.1 time_steps 38880 learning_steps 1944\n",
      "episode 251 score 200.0 avg score 190.1 time_steps 39080 learning_steps 1954\n",
      "episode 252 score 200.0 avg score 190.1 time_steps 39280 learning_steps 1964\n",
      "episode 253 score 200.0 avg score 190.1 time_steps 39480 learning_steps 1974\n",
      "episode 254 score 200.0 avg score 190.1 time_steps 39680 learning_steps 1984\n",
      "episode 255 score 200.0 avg score 190.1 time_steps 39880 learning_steps 1994\n",
      "episode 256 score 200.0 avg score 190.1 time_steps 40080 learning_steps 2004\n",
      "episode 257 score 200.0 avg score 190.1 time_steps 40280 learning_steps 2014\n",
      "episode 258 score 200.0 avg score 190.1 time_steps 40480 learning_steps 2024\n",
      "episode 259 score 200.0 avg score 190.1 time_steps 40680 learning_steps 2034\n",
      "episode 260 score 200.0 avg score 190.1 time_steps 40880 learning_steps 2044\n",
      "episode 261 score 200.0 avg score 190.1 time_steps 41080 learning_steps 2054\n",
      "episode 262 score 200.0 avg score 190.1 time_steps 41280 learning_steps 2064\n",
      "episode 263 score 200.0 avg score 190.1 time_steps 41480 learning_steps 2074\n",
      "episode 264 score 200.0 avg score 190.1 time_steps 41680 learning_steps 2084\n",
      "episode 265 score 200.0 avg score 190.1 time_steps 41880 learning_steps 2094\n",
      "episode 266 score 200.0 avg score 190.1 time_steps 42080 learning_steps 2104\n",
      "episode 267 score 200.0 avg score 190.1 time_steps 42280 learning_steps 2114\n",
      "episode 268 score 200.0 avg score 190.1 time_steps 42480 learning_steps 2124\n",
      "episode 269 score 200.0 avg score 190.5 time_steps 42680 learning_steps 2134\n",
      "episode 270 score 200.0 avg score 190.5 time_steps 42880 learning_steps 2144\n",
      "episode 271 score 200.0 avg score 190.5 time_steps 43080 learning_steps 2154\n",
      "episode 272 score 200.0 avg score 190.5 time_steps 43280 learning_steps 2164\n",
      "episode 273 score 200.0 avg score 190.5 time_steps 43480 learning_steps 2174\n",
      "episode 274 score 200.0 avg score 190.5 time_steps 43680 learning_steps 2184\n",
      "episode 275 score 200.0 avg score 190.6 time_steps 43880 learning_steps 2194\n",
      "episode 276 score 200.0 avg score 190.6 time_steps 44080 learning_steps 2204\n",
      "episode 277 score 200.0 avg score 190.6 time_steps 44280 learning_steps 2214\n",
      "episode 278 score 200.0 avg score 190.6 time_steps 44480 learning_steps 2224\n",
      "episode 279 score 200.0 avg score 190.6 time_steps 44680 learning_steps 2234\n",
      "episode 280 score 200.0 avg score 190.6 time_steps 44880 learning_steps 2244\n",
      "episode 281 score 200.0 avg score 190.6 time_steps 45080 learning_steps 2254\n",
      "episode 282 score 200.0 avg score 191.8 time_steps 45280 learning_steps 2264\n",
      "saving models\n",
      "episode 283 score 200.0 avg score 193.2 time_steps 45480 learning_steps 2274\n",
      "saving models\n",
      "episode 284 score 200.0 avg score 193.8 time_steps 45680 learning_steps 2284\n",
      "episode 285 score 200.0 avg score 193.8 time_steps 45880 learning_steps 2294\n",
      "episode 286 score 200.0 avg score 193.8 time_steps 46080 learning_steps 2304\n",
      "saving models\n",
      "episode 287 score 200.0 avg score 195.0 time_steps 46280 learning_steps 2314\n",
      "episode 288 score 200.0 avg score 195.0 time_steps 46480 learning_steps 2324\n",
      "episode 289 score 200.0 avg score 195.0 time_steps 46680 learning_steps 2334\n",
      "saving models\n",
      "episode 290 score 200.0 avg score 195.8 time_steps 46880 learning_steps 2344\n",
      "episode 291 score 200.0 avg score 195.8 time_steps 47080 learning_steps 2354\n",
      "episode 292 score 200.0 avg score 195.8 time_steps 47280 learning_steps 2364\n",
      "saving models\n",
      "episode 293 score 200.0 avg score 197.5 time_steps 47480 learning_steps 2374\n",
      "episode 294 score 200.0 avg score 197.5 time_steps 47680 learning_steps 2384\n",
      "episode 295 score 200.0 avg score 197.5 time_steps 47880 learning_steps 2394\n",
      "episode 296 score 200.0 avg score 197.5 time_steps 48080 learning_steps 2404\n",
      "episode 297 score 200.0 avg score 197.5 time_steps 48280 learning_steps 2414\n",
      "episode 298 score 200.0 avg score 197.5 time_steps 48480 learning_steps 2424\n",
      "episode 299 score 200.0 avg score 197.5 time_steps 48680 learning_steps 2434\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXwV9fX/8ddJCIQ9IPu+BRBUQFDcte5S61Jr6/JV61K0LnVr3WqVflu72Nr681tri3VfcEex7vvWAoLsArIokBBI2BLWbPf8/pgJXkICgZtkcm/ez8fjPu7cz8ydOZ87c8+d+5nPzJi7IyIiqSUt6gBERKT2KbmLiKQgJXcRkRSk5C4ikoKU3EVEUpCSu4hIClJyT2Jm9oaZXRR1HKnAzJqb2atmVmhmz0ccy/lm9naUMUjyU3JPkJl9Y2ZbzWyTma0ys0fNrFV9LNvdT3H3x+pjWY3AD4DOwD7ufnaUgbj7U+5+Yn0u08yuNrNpZlZsZo9WMf44M1tgZlvM7AMz6x03rpmZPWxmReF34Ib6jF2qpuReO77n7q2A4cAI4NaI40kKZtYk6hji9Aa+cveyRGfUwOpVUyuB3wIPVx5hZh2Al4BfAe2BacCzcZOMA7IJPsPvADeZ2cl1HG+VkvSzrxvurkcCD+Ab4Pi413cDr8W9/hC4LO71j4FP4147cAWwCFgP3A9Y/LTAn8NxXwOnVDXvGkzbF/gY2Ai8Gy7nyWrq1A74N1AQzuvfQI9w3DnAtErTXw9MCoebhTEsB1YD/wCah+OOAXKAm4FVwBO7WlZN4gYOAf4DbABmAcfsYl3tG35mG4B5wGlh+a+BEqAU2ARcWsV7xwEvECS1jcAXwLBK28HNwGygGGgCdANeDOv2NfCzcNpuwFagfdz7RwBrgIwqtpHDgM+BwvD5sF1sf+MqPh8gE3gSWBvW+XOg8262598Cj1YqGwv8J+51yzD+weHrXODEuPG/AZ6pZv4DgI/CuqwBno0bNxR4B1gXbju3xW1T9xL8AK0Mh5tVt02F5acCM8N6/wc4IG45N4cxbwQWAsdFnUfq4qE991pkZj2AU4DFe/jWU4GDgGHAD4GT4saNJtgAOxD8cDxkZlbNfHY17dPAVGAfggRwwS7iSQMeIdgT60XwRf5bOG4SMMjMsuOmPy+cP8AfgYEE/2IGAN2BO+Km7UKw99ebIGnsalm7jNvMugOvESSk9sDPgRfNrGPlCplZBvAq8DbQCbgGeMrMBrn7ncDvCBJNK3d/qJrP5XTg+XBZTwMvh/OtcC7wXSALiIXLmxV+BscB15nZSe6+EvgvcFalz/AFdy+tFHf7sI73hZ/BX4DXzGyfamKMdxHQFugZvvcKgs93Tw0N6wGAu28GlgBDzawdwY/VrLjpZ4XvqcpvCNZBO6AH8H8AZtaa4Mf7zXB+A4D3wvf8kuBHfDjBd+Rg4Pa4ee6wTZnZgQT/QC4nqPc/gUlh89Eg4GrgIHdvTfBd+2aPPo1kEfWvS7I/CDaMTQR7AU6wQWbFjf+Q3e+5HxH3+jnglrhpF8eNaxFO36XyvHc1LUHSLANaxI1/kmr23Kuo43BgfaX33hEOZ4d1bwEYsBnoHzftocDX4fAxBHvImTVZ1u7iJtgDe6LS+98CLqpivkcS7NmlxZVNAMaFw+N29XmE4yfHvU4D8oAj47aDS+LGjwaWV5rHrcAj4fBlwPvhsAErgKMqbyMEP2ZTK83nv8CP45Zb3Z77JVTaa63Buq5qz/0h4A+Vyj4L4+wZbmeZceNOAL6pZv6PA+OJ+3cWlp8LzKjmPUuAMXGvT6qYf1XbFPAA8JtK81gIHE3wo5EPHA9k1PRzScaH9txrxxke7AUcAwwm2HPeE6vihrcAraoa5+5bwsHqDthWN203YF1cGQTJpEpm1sLM/mlmy8ysiKBZJMvM0sNJnib4MkKwx/lyOO+OBEl+upltMLMNBHti8XvSBe6+rYbL2l3cvYGzK5YVLu8IoGsV1eoGrHD3WFzZMoK96pravuxwPjnhfKuLrVul2G4jOGgLQRPPoWbWDTiKIEF+Uk3cyyqV1TTuJwh+7J4xs5Vmdnelfxo1tQloU6msDcGP+qa415XHVeUmgh+zqWY2z8wuCct7EiTxqlT+DJax4+e+wzZF8NnfWOmz7wl0c/fFwHUEP4L5ZvZMuA5SjpJ7LXL3j4BHCdqcK2wmSHgVutRnTKE8oL2ZxcfRcxfT3wgMAka7exuC5APBlxKCv9UdzGw4QZKvaJJZQ/C3f6i7Z4WPth4cbK5Q+TKku1rW7uJeQbDnnhX3aOnuf6iiTiuBnmYWv833Imh7rantyw7n0yOcb1V1W0HwjyU+ttbuPgbA3TcQfI4/JPiBnODhLmYVcfeuVBYfd7Xbl7uXuvuv3X0IQbv9qcCFNa7tt+YRNIcAYGYtgf7APHdfT7CehsVNPyx8z07cfZW7/8TduxE0m/zdzAYQfF79q1l+5c+gF9V/7oTzuqvSZ9/C3SeEMTzt7keE83SCpsSUo+Re++4FTggTHwQHdb4f7qEOAC6t74DcfRlBD4dxZtbUzA4FvreLt7QmSNIbwjbfOyvNr4xgz/NPBG2d74TlMeBB4K9m1gmCdnEziz+GUONl1SDuJ4HvmdlJZpZuZplmdkx47KOyKQSJ8CYzyzCzY8J5PbOL2CobaWbfD3tkXEdw4HRyNdNOBYrM7OawD326me1nZgfFTfM0QbI9i29/ICt7HRhoZueZWRMz+xEwhODAMwTb1zlhnUYRdOkEwMy+Y2b7h/+CiggOGJdXtZBw3plAOlDxWVb0PJkI7GdmZ4XT3AHMdvcF4fjHgdvNrJ2ZDQZ+QrCTU9Vyzo5bP+sJkmt5WJ8uZnZd2Dbe2sxGh9NNCOffMey5cwfBuq/Og8AVZjbaAi3N7LvhPAeZ2bFm1gzYRrDtVfmZJDsl91rm7gUEG/uvwqK/ErQJrgYeA56KKLTzCdq/1xK0qz5LkJyqci/QnGBPfDJB00plTxO0Wz7vO3YfvJnggPLksJnlXYI98+rsblnVxu3uKwgOct5G0CNlBfALqtiu3b0EOI3ggPca4O/AhXEJqiZeAX5EkJQuAL7vlQ6Axi2vnODHYzhBT5k1wL8IDnBWmERwzGK1u8/aaSbBfNYS7HHfSPAZ3ASc6u5rwkl+RbDHu56g10/8j0QXgh/hImA+QS+V6pLi7QSJ7hbgf8Lh28MYCgh+gO4KlzOaoNdUhTsJmlSWhcv4k7tXtc1A0HFgipltCut/rbt/7e4bCdrqv0fQvLiIoFslBOt9GkFPpDkEPZV+W838cfdpBD8wfwvjXUxwfACCnjd/IFgfqwgOrt9W3bySWUWXO2lkzOxZYIEHPUWSRlRxm9k4YIC7/099Lldkb2nPvZEws4PMrL+ZpVlwgsnpwMtRx7U7yRq3SNR0Nlfj0YXgLMN9CHp5/NTdZ0QbUo0ka9wikVKzjIhIClKzjIhICmoQzTIdOnTwPn36RB2GiEhSmT59+hp33+lyG9BAknufPn2YNm1a1GGIiCQVM6t89vJ2apYREUlBSu4iIilot8ndzHpacOeV+eGFfq4Ny9ub2Ttmtih8bheWm5ndZ2aLzWy2BZffFBGRelSTPfcy4EZ335fgmspXmdkQgtOU33P3bILL3N4STn8KwSnV2QTX636g1qMWEZFd2m1yd/c8d/8iHN5IcI2K7gRnClbcv/Mx4Ixw+HTgcQ9MJrh8a1WXYBURkTqyR23uZtaH4HZgUwhu15UHwQ8AwQV4IEj88de1zmHPrpktIiIJqnFyN7NWBPeDvM7di3Y1aRVlO50Ga2ZjLbjb+rSCgoKahiEiIjVQo37u4d1bXgSecveXwuLVZtbV3fPCZpf8sDyHHW+oUPmGBgC4+3iC220xatQoXQNBRFLaO1+uZk7Ohp3KB3ZpzakH1P7NoHab3M3MCO6hON/d/xI3ahLBDXj/ED6/Eld+tZk9Q3Dd58KK5hsRkcZods4GfvJ4cKJm5dvbn3pAt2iSO3A4wY0J5pjZzLDsNoKk/pyZXQosB84Ox70OjCG4QP4W4OJajVhEJAkUbinl92/MJ3fDVpbkb6JDq2Z88POjaZ25N7ex3XO7Te7u/ilVt6MDHFfF9A5clWBcIiJJp2BjMVc8OZ3c9VvZXFzGtrJy9uvelm5Zzbn62AH1ltihgVxbRkQkWS1bu5nxHy+lcGsp8/OKyN2wldOGdSM9LY0fjOzByN7tIolLyV1EIlMec6Z+vY7BXVrTrmXTqMPZYwtWFXHG/Z9hGF2zMslIS+P/zj2QE4Z0jjo0JXcR2Xu5G7Yy8Ysc3p2fT3FZbI/e6+6sKtrGhi2lDOvRlueuOJRmTdLrKNLaV1xWzo3PzaJl0ya8es0RdMtqHnVIO1ByF5E9Uh5z/j17Jc9Py+GzJWtwh5G929Gj3Z4ntxG9sujYOpP73lvEr1/9kt+duX8dRLx7ZeUxFqzaSFnMdypfs6mYWBWdtd+cu4p5K4sYf8HIBpfYQcldRPbApuIyrp0wg/cW5NOzfXOuPS6bsw7sQc/2LRKab0lZjH98tIQl+Zto2iSNirt/enj+4/bX1ZVXzGg34ytuK/rt6+B55Yat5G8s3uO4f3ZcNicO7bLH76sPSu4iUiMrN2zlkkc/Z1H+Jv739KH8z+jepKVV15Fuz/z8xIFs3FbKl3lFlJTHtnfPs7BT+Levw2e2D+w4Pq3iddq301Z6T+V+5mZG96zmnDi0M20q9WZJSzP2admUjPSdT+bPzEij9z4t97Cm9UfJXUR2qaw8xqRZK/n9GwvYVlLOwz8+iKMHVnlnt73WJD2NuyJqkklVSu4iUq1Fqzdy3bMzmbeyiEGdW3PfpSMY1KV11GFJDSi5i6SwrSXlfL1mMzF33CHmHj6C9udYWLZucwnfrN28vQ06v2gbs3MLWbhqIy2apnP/eQcyZv8u25tJpOFTchdJUZ9/s45rJ8xgZeG2PX5vsyZpjOiVxUlDu3DzyYPp0jazDiKUuqTkLpKCXp+Tx3XPzKR7u+bc+6PhtGiaTpoZaWnBAcQ0M9IM0swwg9bNMujfqSXp4QHSJmlp24clOSm5i6QQd+ev7y7ivvcWMaJXFo/8+CCyWiTfmZ+SOCV3kRRx77tf8c6Xq5m3soizR/bgt2ful1RnfErt2qPb7IlIwzRj+XrufXcRJWUxrj0umz+edYASeyOnPXeRJLKlpIxxk+bRrEk6/Tq2ZMW6rQzr2ZZ/fLSUjq2bMfGqw2nVTF9rUXIXaRC2lZazubhsp/I0s+1XS4zFnIsf+ZzPv1lHk7Q0SspjZKQbD3/mmMFDF41SYpfttCWIRGzZ2s2ccf9nrN9SWuX4cw/uye/O3J/np69gytfr+MP39+eU/bpSGovRtnkG//f+Yrq0yeTYwdFfZlYaDiV3kQgtX7uFW16cQ2m5M+57Q3a6Vsu83CImTF3BRwsLWFm4jZG92/Gjg3rucDLRDScMrO+wJQnU5AbZDwOnAvnuvl9Y9iwwKJwkC9jg7sPNrA8wH1gYjpvs7lfUdtAiyao85rw2J4/Vhdv4Yvl63py3Cnf4/ff359yDe+00fSzm9GzfnEX5m8ju1IpzDu6ls0SlRmqy5/4o8Dfg8YoCd/9RxbCZ3QMUxk2/xN2H11aAIskod8NWXpqeQ3FZjNLyGKuKtmFAzGHSrJUAtGuRwRVH9+fcg3rRa5+qL5mblmZcfWx2PUYuqaImN8j+ONwj34kFuxA/BI6t3bBEktdHXxUw9vFpFJfFSE8z0s3o3LYZW0uCGz9ceGhvbjxhEG2aN9FeuNSZRNvcjwRWu/uiuLK+ZjYDKAJud/dPqnqjmY0FxgL06rXz31GRZLRi3RaufvoL+nZoyUM/PojucXfoKY858/OKGNK1Ta1dB12kOomexHQuMCHudR7Qy91HADcAT5tZm6re6O7j3X2Uu4/q2LF2rw0tEpW731pIWbnz4IWjdkjsAOlpxn7d2yqxS73Y6+RuZk2A7wPPVpS5e7G7rw2HpwNLAB3Kl0Zhbm4hr85aySVH9En4tnMiiUpkz/14YIG751QUmFlHM0sPh/sB2cDSxEIUSQ5/emshbZtnMPao/lGHIrL75G5mE4D/AoPMLMfMLg1HncOOTTIARwGzzWwW8AJwhbuvq82ARRqaKUvXcsJfPuKjrwq48pj+tG2esfs3idSxmvSWObea8h9XUfYi8GLiYYk0bCvWbeHd+aspjzkPfrKUjPQ0rvpOfy46rE/UoYkAOkNVZI8UbSvlnrcW8vTU5ZSWB/eka53ZhAk/OYj9ureNODqRbym5i9SQu/OL52fx7vx8fjiqJz89uj9ZLTNo1iRNl9eVBkfJXaQG3IPml7fmreaWUwZzxdE6aCoNm5K7yG5s2FLCbRPn8PqcVZwwpDOXHdE36pBEdkvJXaQahVtLeWVmLn//YAlrNhVz88mDufyofjoJSZKCkrtIFfI3buOCf01l4eqNDO7SmgcvHMX+PXTAVJKHkrtInM3FZYz/eCn/+mQp5e48dsnBHD1Ql8eQ5KPkLhKKxZwrnpzOJ4vWcMp+XbjxxEEM6NQq6rBE9oqSu0joySnL+GTRGn5z+lAuOLRP1OGIJCTRq0KKpIT1m0v481sLOWJAB/7nkN5RhyOSMCV3afTKY87tr8xlc0k5d3xviG6gISlBzTLSqK3dVMwtL83hnS9Xc/PJgxnYuXXUIYnUCiV3aXRiMeeNuauYuWI9E2fkUrS1jF+dOoRLdXKSpBAld2lU3J2rnv6CN+auoml6Gvt2a8OTl+3P4C5V3jBMJGkpuUujMmnWSt6Yu4prj8vm2uOydbappCwdUJVGY82mYsZNmsfwnln8TIldUpySuzQKJWUxbnphNpuKy7j7BweQrsQuKa4mt9l72MzyzWxuXNk4M8s1s5nhY0zcuFvNbLGZLTSzk+oqcJGaisWcayZ8wfsL8rnj1CHqESONQk323B8FTq6i/K/uPjx8vA5gZkMI7q06NHzP3ytumC0SlXvfW8Rb81bzq1OH6MxTaTR2m9zd/WOgpje5Ph14xt2L3f1rYDFwcALxiSRkxvL1/O39RZx1YA8uObxP1OGI1JtE2tyvNrPZYbNNu7CsO7AibpqcsGwnZjbWzKaZ2bSCgoIEwhCp2rbScn7xwmy6tMlk3Gk681Qal71N7g8A/YHhQB5wT1he1bfHq5qBu49391HuPqpjR11SVWrffe8tYnH+Jn5/1gG0zsyIOhyRerVXyd3dV7t7ubvHgAf5tuklB+gZN2kPYGViIYrsuRXrtvDgJ0s568Aeuh67NEp7ldzNrGvcyzOBip40k4BzzKyZmfUFsoGpiYUosuf+/PZC0tOMX5w0KOpQRCKx2zNUzWwCcAzQwcxygDuBY8xsOEGTyzfA5QDuPs/MngO+BMqAq9y9vG5CF6na3NxCXpm5kiuP6U+XtplRhyMSid0md3c/t4rih3Yx/V3AXYkEJZKIP765gKwWGVx+dP+oQxGJjM5QlZTy6aI1fLJoDVd/ZwBtm+sgqjReSu6SMsrKY/zu9fl0z2rOBYfqbkrSuCm5S8p4+LOv+TKviFvHDKZZE50YLY2bLvkrKeHOV+by2H+Xcfy+nfnu/l13/waRFKfkLknvs8VreOy/yzhvdC9+9V2diSoCSu6S5Mpjzh/eWED3rObcceoQMjPUHCMCanOXJObuPDVlGXNyC/nFSYOU2EXiaM9dktKWkjLOGT+Z2TmFHNZ/H04f3i3qkEQaFCV3SUr3vP0Vs3MKufnkwZw3upfa2UUqUXKXpPPHNxfw0Kdfc/7oXvz0GJ2FKlIVtblLUvn4qwIe+HAJ5xzUk3GnDY06HJEGS8ldkkZJWYzfvvYlvdq34NenDyUjXZuvSHX07ZCkcc87C/lq9SZ+deoQnYEqshtK7pIUZixfz/iPl3Le6F6cMKRz1OGINHhK7tLgFZeVc9vEuXRpk8ltY/aNOhyRpKDeMtKguTvjJn3J/LwiHrxwFK2aaZMVqQl9U6TBKi4r55qnZ/D2l6u54uj+ao4R2QNK7tJg/e61+bz95Wpu/+6+XHpE36jDEUkqu21zN7OHzSzfzObGlf3JzBaY2Wwzm2hmWWF5HzPbamYzw8c/6jJ4SU0btpRw0wuzeOy/y7j0iL5cdmQ/nYEqsodqckD1UeDkSmXvAPu5+wHAV8CtceOWuPvw8HFF7YQpjcVni9dw9J8+5PnpOVx5TH8dQBXZSzW5QfbHZtanUtnbcS8nAz+o3bCkMXrpixxuemE2/Tu24tnLD2FwlzZRhySStGqjK+QlwBtxr/ua2Qwz+8jMjqzuTWY21symmdm0goKCWghDktlTU5Zxw3OzOKhPe5674lAldpEEJZTczeyXQBnwVFiUB/Ry9xHADcDTZlblt9Tdx7v7KHcf1bFjx0TCkCT3wvQcfjlxLscO7sSjlxxE2+YZUYckkvT2Ormb2UXAqcD57u4A7l7s7mvD4enAEmBgbQQqqenTRWu46YVZHDGgA38//0BdVkCkluxVcjezk4GbgdPcfUtceUczSw+H+wHZwNLaCFRSz/rNJdzw3Ez6dmjJ+AtH6k5KIrVotwdUzWwCcAzQwcxygDsJesc0A94Ju6hNDnvGHAX8r5mVAeXAFe6+ro5ilyTm7tzy0mzWbynhkYsPokVTnXIhUptq0lvm3CqKH6pm2heBFxMNSlLfpFkreWvean45Zl+GdmsbdTgiKUcXDpN6t3FbKXe9Np9hPdrqzFOROqL/wlLv/vbBYvI3FvPPC0aSlqYzT0XqgvbcpV4tW7uZRz79hrMO7MGIXu2iDkckZSm5S72667X5NEk3bjp5UNShiKQ0JXepN2/MyePtL1dz1XcG0LlNZtThiKQ0JXepF/Pzirju2ZkM75mlg6gi9UDJXerFXa/Np0XTdB66aJROVhKpB0ruUuc+WVTAp4vXcM2x2ezTqlnU4Yg0CkruUqfcnbvfXEj3rOacf0ivqMMRaTSU3KVOvTl3FXNyC7n+hIG6KJhIPVJylzpTHnP+/PZCBnRqxZkjukcdjkijouQudealL3JYUrCZn584kHSdiSpSr5TcpU4Ul5Vz77uLOKBHW04a2iXqcEQaHSV3qRPPTF1B7oat/OKkQYSXhRaReqTkLrVuS0kZ//f+Yg7p154jBnSIOhyRRknJXWpVcVk5Nz43izWbivnFSYO11y4SEV3yV2pNSVmMq576gnfn53P7d/dlZG9d9VEkKjXaczezh80s38zmxpW1N7N3zGxR+NwuLDczu8/MFpvZbDM7sK6Cl/pTHnO2lpRXO76sPMa1z8zg3fn5/OaM/bjsyH71GJ2IVFbTZplHgZMrld0CvOfu2cB74WuAUwhujJ0NjAUeSDxMiVJZeYyfPD6N/ce9xWWPTWN10bYdxpfHnBuem8Ubc1fxq1OHcMEhvSOKVEQq1KhZxt0/NrM+lYpPJ7hxNsBjwIfAzWH54+7uwGQzyzKzru6eVxsBS/2KxZxbX5rD+wvyOW1YN975cjVj/t8nXH/CQDZuK2NO7gZm5xSSs34rN588WFd8FGkgEmlz71yRsN09z8w6heXdgRVx0+WEZTskdzMbS7BnT69euuZI1Gau2MCW4jIO7N2OjPQ00tMMd+eOSXN5fnoO1x6XzfUnDGRx/kaufnoGt78ctND17dCSwV1ac+sp+/LdA7pGXAsRqVAXB1Sr6h7hOxW4jwfGA4waNWqn8VJ/Fq3eyHkPTmZLSTlpBl3bNufiw/vw8aI1fPxVAZcf3Y/rjs8GYECn1rx6zRF8s2Yz7Vo2pYOu8ijSICWS3FdXNLeYWVcgPyzPAXrGTdcDWJnAcqQObSkp46dPfUGLpunccMJA1m4u4ZUZufz2tfl0aZPJL04axJXH9N+hS2NGehrZnVtHGLWI7E4iyX0ScBHwh/D5lbjyq83sGWA0UKj29obr15O+ZEnBJp64ZDRHZAcnHF17XDbrNpfQtW2m+qmLJKkaJXczm0Bw8LSDmeUAdxIk9efM7FJgOXB2OPnrwBhgMbAFuLiWY5Za8srMXJ6dtoKrvtN/e2IHyMxIp1tW8wgjE5FE1bS3zLnVjDquimkduCqRoKTuLVu7mV9OnMvI3u24/viBUYcjIrVMlx9ohMrKY/xswgzSDO47dwRN0rUZiKQaXX6gEXrgwyXMyink/vMOpLuaX0RSknbZGpl5Kwv5f+8t4rRh3dQvXSSFac+9kVhasImWzZpw43OzaNeyKf97+tCoQxKROqTk3ghM+2Yd5/1rCu5Oabnz8I9HkdWiadRhiUgdUnJPcf9ZsobLn5hOt7aZNGuSzmED9uHYwZ2jDktE6piSewpbtHojlzz6OT3bteCRiw+iR7sWUYckIvVEyT1FlZbHuGbCDFo1a8JTPxlNp9aZUYckIvVIyT0FFW4t5ZHPvmbBqo2Mv2CkErtII6TknmJWF23jpHs/ZsOWUo4d3IkTh3aJOiQRiYCSe4r545sL2FJczr0/Gs5JSuwijZaSewqZsXw9L32Ry+VH9+OMEd2jDkdEIqQzVFNELOaMe/VLOrZuxjXHZkcdjohETMk9RUyckcusFRu4+eTBtGqmP2QijZ2SewrYUlLGH99cwLCeWXxfzTEigpJ7SnjsP8vI31jMHafuS1qa7pwkIkruSa9oWyn/+GgJ3xnUkZG920cdjog0EEruSWRTcRm3vjSbWSs2bC97+NOvKdxayg0nDIowMhFpaPb6yJuZDQKejSvqB9wBZAE/AQrC8tvc/fW9jlC2e+K/y5gwdQX/np3HU5eNpk1mBv/65GtOHtqF/Xu0jTo8EWlA9jq5u/tCYDiAmaUDucBEghti/9Xd/1wrEQrrNpdw/bMzmbF8PSN6ZVGwsZjz/zWFFk3TyUg3bh0zOOoQRaSBqa0+c8cBS9x9mZkO6NW2Jycv46OvCujVvgW/OnUIHVs147aJcyiPOT8/aRC992kZdYgi0sDUVnI/B5gQ9/pqM7sQmAbc6O7rK7/BzMYCYwF69epVS2GknpKyGE9MXsbRAzvy2CUHby9/4tLREUYlIg1dwgdUzawpcBrwfFj0ANCfoMkmD7inqve5+3h3H+Xuozp27JhoGCnrtTkrKdhYzMWH94k6FBFJIj97ZpcAAA1FSURBVLXRW+YU4At3Xw3g7qvdvdzdY8CDwMG7fLdUy9155LNv6NexJUdl6wdQRGquNpL7ucQ1yZhZ17hxZwJza2EZjdKHCwuYnVPIxYf10clJIrJHEmpzN7MWwAnA5XHFd5vZcMCBbyqNkxoq3FrKrS/NIbtTK84e1TPqcEQkySSU3N19C7BPpbILEoqokSstj/HRwgL+PXslBZuK+ecFI8nMSI86LBFJMrp8YAPi7tz84mxe+iIXgCuP6c+wnlkRRyUiyUjJvQG5991FvPRFLj85si+Du7The8O6RR2SiCQpJfcG4o05efy/9xbxg5E9uG3MvuhkMBFJhC4c1gDkb9zGrRPnMKxHW3535v5K7CKSMCX3BuCfHy1l47Yy7vnhcJo20SoRkcQpk0Rs/eYSJkxdzunDujGgU6uowxGRFKHkHqH1m0u48OGpFJfFuOKY/lGHIyIpRMk9Qr9/Yz4LVhXx4IUjGdi5ddThiEgKUXKPyPy8Ip6fnsNFh/bh2MGdow5HRFKMkns9isWc/KJtAPzt/cW0atqEa47NjjgqEUlF6udeT0rLY/xswgzenLeK74/owetz8/jp0f1p2yIj6tBEJAVpz72e/O39xbwxdxWH9tuHl2fm0ql1My45om/UYYlIitKeez1Ys6mYBz9Zypj9u/D380fi7jpRSUTqlPbc68EDHy5hW2k5N5wwCECJXUTqnJJ7HVu5YStPTF7GWQf20ElKIlJvlNzr2FNTllEec649Xr1iRKT+KLnXsU8XrWFEzyx6tGsRdSgi0ogknNzN7Bszm2NmM81sWljW3szeMbNF4XO7xENNPoVbSpmdW8jhAzpEHYqINDK1tef+HXcf7u6jwte3AO+5ezbwXvi60fnv0jW4wxHZSu4iUr/qqlnmdOCxcPgx4Iw6Wk6D9va81bTObMKwHrpVnojUr9pI7g68bWbTzWxsWNbZ3fMAwudOld9kZmPNbJqZTSsoKKiFMOrH3W8uYPTv3uXnz8+ipCxW7XRF20p5fW4epw3rpmu0i0i9q42TmA5395Vm1gl4x8wW1ORN7j4eGA8watQor4U46lxZeYynpiynTfMmvDA9h7Wbirn3nBG0bf7tJQSmfr2OiTNyKdhYzLbSGGeP6hlhxCLSWCWc3N19Zficb2YTgYOB1WbW1d3zzKwrkJ/ocqL09JTlTF66lh7tmlO4tZTfnbk/G7aWcOcr8zjz/s8Yf+FImjdtQvOMdK5/diari7bRomk6Fx3am2E92kYdvog0QgkldzNrCaS5+8Zw+ETgf4FJwEXAH8LnVxINNEr3f7CY3A1bt78+cmAH2mRmkN2pNZc8+jnH/+XjHaZ/duwhjO63T32HKSKyXaJ77p2BieHp9E2Ap939TTP7HHjOzC4FlgNnJ7icyGzcVkruhq1ceUx/5uQW0r5lU9pkBs0wB/dtz0tXHsZ/Fq+hedN08ouKad+qqRK7iEQuoeTu7kuBYVWUrwWOS2TeDcXCVRsBOLBXO246eTDuOx4eGNi5te6iJCINjrpx7Mb8vCIA9u3WBtBFv0QkOSi578aXeRtpk9mEbm0zow5FRKTGlNx3YdykeUyYupz9urfVHruIJBUl92psLSnn6anLOW5wJ/541gFRhyMiskeU3Ksx5eu1lJTFuOiwPvRsrys6ikhy0W32Qne/uYCPvirgByN7kL+xmAc+XAIE3R1FRJKNkjuQs34Lf/9wCfu0bMqvX/1ye/mxgzuRmZEeYWQiIntHyR14eUYuABPGHsL1z86kb4eW3HLKYFo108cjIsmp0Wav8phz/r8mM29lEVtKyhndtz0DO7fm1auPIC1NPWNEJLk12uT+5txVTF66jtOGdaNr20xOG94NQIldRFJCo0vu5THnjPs/Y1H+Rvp1aMlffzScdCV0EUkxjS65z1yxnjm5hYzolcXPjstWYheRlNTokvu78/NpkmY8evHBO9xkQ0QklTSK5F4ec25/eS5HZXfg7XmrOKhPeyV2EUlpjSK5z87ZwISpy5kwdTkAVx87IOKIRETqVqNI7h8uDG7AfWR2B84Y3p0zR/SIOCIRkbrVOJL7VwWM6JXFE5eOjjoUEZF6sdcXDjOznmb2gZnNN7N5ZnZtWD7OzHLNbGb4GFN74e6ZzcVlXPTwVGat2MDx+3aOKgwRkXqXyJ57GXCju39hZq2B6Wb2Tjjur+7+58TD23vuzs+fn8Uniwq45ZTBXHJ43yjDERGpV3ud3N09D8gLhzea2Xyge20FlqjX56zijbmruPWUwVx+dP+owxERqVe1cj13M+sDjACmhEVXm9lsM3vYzNrVxjJqaltpORc/MpVfvjyHwV1ac9mR/epz8SIiDULCyd3MWgEvAte5exHwANAfGE6wZ39PNe8ba2bTzGxaQUFBomFst6RgEx8sLGDDllLuOnN/nYEqIo1SQsndzDIIEvtT7v4SgLuvdvdyd48BDwIHV/Vedx/v7qPcfVTHjh0TCWMHqwq3ATDxysMY2bte/zSIiDQYifSWMeAhYL67/yWuvGvcZGcCc/c+vD23Mkzu3bKa1+diRUQalER6yxwOXADMMbOZYdltwLlmNhxw4Bvg8oQi3EOrCrfSJM3o0KpZfS5WRKRBSaS3zKdAVQ3ar+99OInL27CNzm0y1dYuIo1arfSWaUjyCrfRpW1m1GGIiEQqBZP7VroquYtII5dSyd3dySvcpuQuIo1eSiX3tZtLKC6L0bWtesqISOOWUsn9nrcXYob6t4tIo5cyyf31OXlMmLqCy4/qz7CeWVGHIyISqZRI7us2l3DLi7MZ1qMtN544MOpwREQilxLJ/bXZKynaVsZdZ+5PRnpKVElEJCFJfSem8pjz5ORlPD99BdmdWjG0W5uoQxIRaRCSOrlPXrqWOyfNA+D64wcSXO5GRESSOrkfPqADE688jJdn5HL+Ib2iDkdEpMFI6uQOMKJXO0b0UtdHEZF4OvooIpKClNxFRFKQkruISApSchcRSUFK7iIiKUjJXUQkBSm5i4ikICV3EZEUZO4edQyYWQGwbC/f3gFYU4vhRCVV6gGqS0OlujRMidSlt7t3rGpEg0juiTCzae4+Kuo4EpUq9QDVpaFSXRqmuqqLmmVERFKQkruISApKheQ+PuoAakmq1ANUl4ZKdWmY6qQuSd/mLiIiO0uFPXcREalEyV1EJAUlbXI3s5PNbKGZLTazW6KOZ0+Z2TdmNsfMZprZtLCsvZm9Y2aLwucGeRcSM3vYzPLNbG5cWZWxW+C+cD3NNrMDo4t8Z9XUZZyZ5YbrZqaZjYkbd2tYl4VmdlI0Ue/MzHqa2QdmNt/M5pnZtWF50q2XXdQlGddLpplNNbNZYV1+HZb3NbMp4Xp51syahuXNwteLw/F99nrh7p50DyAdWAL0A5oCs4AhUce1h3X4BuhQqexu4JZw+Bbgj1HHWU3sRwEHAnN3FzswBngDMOAQYErU8degLuOAn1cx7ZBwW2sG9A23wfSo6xDG1hU4MBxuDXwVxpt062UXdUnG9WJAq3A4A5gSft7PAeeE5f8AfhoOXwn8Ixw+B3h2b5edrHvuBwOL3X2pu5cAzwCnRxxTbTgdeCwcfgw4I8JYquXuHwPrKhVXF/vpwOMemAxkmVnX+ol096qpS3VOB55x92J3/xpYTLAtRs7d89z9i3B4IzAf6E4Srpdd1KU6DXm9uLtvCl9mhA8HjgVeCMsrr5eK9fUCcJyZ2d4sO1mTe3dgRdzrHHa98hsiB942s+lmNjYs6+zueRBs4ECnyKLbc9XFnqzr6uqwueLhuOaxpKhL+Fd+BMFeYlKvl0p1gSRcL2aWbmYzgXzgHYJ/FhvcvSycJD7e7XUJxxcC++zNcpM1uVf1S5ZsfToPd/cDgVOAq8zsqKgDqiPJuK4eAPoDw4E84J6wvMHXxcxaAS8C17l70a4mraKsodclKdeLu5e7+3CgB8E/in2rmix8rrW6JGtyzwF6xr3uAayMKJa94u4rw+d8YCLBSl9d8dc4fM6PLsI9Vl3sSbeu3H11+IWMAQ/y7V/8Bl0XM8sgSIZPuftLYXFSrpeq6pKs66WCu28APiRoc88ysybhqPh4t9clHN+Wmjcb7iBZk/vnQHZ4xLkpwYGHSRHHVGNm1tLMWlcMAycCcwnqcFE42UXAK9FEuFeqi30ScGHYO+MQoLCimaChqtT2fCbBuoGgLueEPRr6AtnA1PqOryphu+xDwHx3/0vcqKRbL9XVJUnXS0czywqHmwPHExxD+AD4QThZ5fVSsb5+ALzv4dHVPRb10eQEjkKPITiKvgT4ZdTx7GHs/QiO7s8C5lXET9C29h6wKHxuH3Ws1cQ/geBvcSnBnsal1cVO8Dfz/nA9zQFGRR1/DeryRBjr7PDL1jVu+l+GdVkInBJ1/HFxHUHw9302MDN8jEnG9bKLuiTjejkAmBHGPBe4IyzvR/ADtBh4HmgWlmeGrxeH4/vt7bJ1+QERkRSUrM0yIiKyC0ruIiIpSMldRCQFKbmLiKQgJXcRkRSk5C4ikoKU3EVEUtD/B24AQswI8b2zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from utils import plot_learning_curve\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N = 20\n",
    "batch_size = 5\n",
    "n_epochs = 4\n",
    "alpha = 0.0003\n",
    "agent = Agent(n_actions=env.action_space.n, batch_size = batch_size,\n",
    "             alpha = alpha, n_epochs = n_epochs, \n",
    "              input_dims = env.observation_space.shape)\n",
    "\n",
    "n_games = 300\n",
    "\n",
    "figure_file = 'plots/cartpole.png'\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        agent.save_models()\n",
    "\n",
    "    print('episode', i, 'score %.1f' %score, 'avg score %.1f' %avg_score, \n",
    "          'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "        \n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, figure_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
